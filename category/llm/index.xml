<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM | Shaojie Jiang&#39;s Homepage</title>
    <link>https://shaojiejiang.github.io/category/llm/</link>
      <atom:link href="https://shaojiejiang.github.io/category/llm/index.xml" rel="self" type="application/rss+xml" />
    <description>LLM</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 13 Aug 2023 17:05:13 +0200</lastBuildDate>
    <image>
      <url>https://shaojiejiang.github.io/media/icon_huf1850796dc0c27e76df1b37fe2f35b33_25680_512x512_fill_lanczos_center_3.png</url>
      <title>LLM</title>
      <link>https://shaojiejiang.github.io/category/llm/</link>
    </image>
    
    <item>
      <title>Has the era of AI gaming already come?</title>
      <link>https://shaojiejiang.github.io/post/en/ai-gaming-era/</link>
      <pubDate>Sun, 13 Aug 2023 17:05:13 +0200</pubDate>
      <guid>https://shaojiejiang.github.io/post/en/ai-gaming-era/</guid>
      <description>&lt;p&gt;With the big noises made by ChatGPT, many different industries have noticed the value of LLM technologies.
Unsurprisingly, the gaming industry is one of them.
In this blog, I introduce several cool demos/WIPs that I&amp;rsquo;ve recently found, and share my opinions on why they might have profound influences on the future of gaming industry.
I also try to explain the current difficulties, and possible directions for solving them.
In the end, I also share some dreams of future games.
I believe, the era of AI gaming has come!&lt;/p&gt;
&lt;h2 id=&#34;the-matrix-ai-powered-npcs-demo-by-the-replica-studios&#34;&gt;The Matrix AI-Powered NPCs demo by the Replica Studios&lt;/h2&gt;
&lt;p&gt;Players are used to have chats with the NPCs, but most of these conversations are scripted.
The current best conversational experience you can have with NPCs is to select from several possible responses, so you have some freedom of steering dialogues.&lt;/p&gt;


















&lt;figure  id=&#34;figure-dialogue-selection-in-witcher-3&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Dialogue selection in Witcher 3&#34; srcset=&#34;
               /post/en/ai-gaming-era/figures/dialogues-in-witcher3_hue09e192b7ac8a4706bd7f9ae742b8051_48100_527b0774b1c015883502fc1666882b7e.webp 400w,
               /post/en/ai-gaming-era/figures/dialogues-in-witcher3_hue09e192b7ac8a4706bd7f9ae742b8051_48100_2c0e283be5301be66b25147cae746fe8.webp 760w,
               /post/en/ai-gaming-era/figures/dialogues-in-witcher3_hue09e192b7ac8a4706bd7f9ae742b8051_48100_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://shaojiejiang.github.io/post/en/ai-gaming-era/figures/dialogues-in-witcher3_hue09e192b7ac8a4706bd7f9ae742b8051_48100_527b0774b1c015883502fc1666882b7e.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Dialogue selection in Witcher 3
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;If you are a game lover, have you ever dreamt about talking to NPCs like they&amp;rsquo;re other human players?
Well, this is definitely possible now, and the Replica Studios already made a demo about it&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.
Instead of looping over pre-scripted lines, the Replica Studios attached LMs (probably OpenAI ChatGPT) to the NPCs, allowing them to all speak characteristically.
You can even chat with NPCs using your voices directly, and they will speak back.
Take a look at this YouTube video&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; of the demo.&lt;/p&gt;
&lt;p&gt;In many games, the plot is driven (or better put, reflected) by chatting with NPCs.
But since LLM chatbots can have randomness in their responses, maybe in the future, the game progression can be take to anywhere, so that every player can have a unique experience in the same game.
This is already partly made true in the AI Dungeon text game&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;The Matrix demo may look sleek in the video, but in reality it can take around 10 seconds to get a response from NPCs.
This lag is probably due to many users are calling the LLM API at the same time, and slow processing of several different modules, such as ASR and TTS.
Besides, current general-purpose LLMs like ChatGPT are very large in terms of number of parameters, and this means long processing time.
Potential solutions can be training bespoke, smaller-sized chatbot models, and maybe even audio-to-audio model so that the processing is simplified.&lt;/p&gt;
&lt;h2 id=&#34;herika-by-dwemer-dynamics&#34;&gt;Herika by Dwemer Dynamics&lt;/h2&gt;
&lt;p&gt;The experience that every player being able to conduct unique conversations with each NPC can already be fascinating.
Isn&amp;rsquo;t it more interesting to have a computer-controlled companion, one that can not only chat with you, but can also follow your voice commands?
Then you definitely want to check out Herika, a mod&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; for &lt;em&gt;The Elder Scrolls V: Skyrim&lt;/em&gt;.
Herika is a ChatGPT-powered AI companion that can understand the player&amp;rsquo;s audio and textual inputs.
She is capable of chit-chatting with the player, commenting on the game scenes and events, following the player&amp;rsquo;s various commands, and more.&lt;/p&gt;


















&lt;figure  id=&#34;figure-system-design-of-herika-image-credit-dwemer-dynamics&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;System design of Herika. Image credit: Dwemer Dynamics&#34; srcset=&#34;
               /post/en/ai-gaming-era/figures/herika-system_hu29424bab3769eb4f68d9166875cc0864_509908_8ef29e5e73f8099642bfabb22652b4d5.webp 400w,
               /post/en/ai-gaming-era/figures/herika-system_hu29424bab3769eb4f68d9166875cc0864_509908_76bd25ffc50f49e25b364c14c33177b2.webp 760w,
               /post/en/ai-gaming-era/figures/herika-system_hu29424bab3769eb4f68d9166875cc0864_509908_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://shaojiejiang.github.io/post/en/ai-gaming-era/figures/herika-system_hu29424bab3769eb4f68d9166875cc0864_509908_8ef29e5e73f8099642bfabb22652b4d5.webp&#34;
               width=&#34;760&#34;
               height=&#34;418&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      System design of Herika. Image credit: Dwemer Dynamics
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Above is an illustration of Herika&amp;rsquo;s system design.
Here is a brief overview of its main components:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Audio inputs and outputs are processed to and from texts by ASR and TTS modules&lt;/li&gt;
&lt;li&gt;Game objects, scenes, locations, etc., are extracted from the game as texts&lt;/li&gt;
&lt;li&gt;The chatting and commenting are all achieved by querying the OpenAI API, in the form of role-playing chats&lt;/li&gt;
&lt;li&gt;Given player&amp;rsquo;s command in natural language, the command-following ability is achieved by asking GPT to generate formatted commands that are used by the game engine to control Herika&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Check out this YouTube video&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; to get the feeling of how Herika works.
Although it seems to work astonishingly well in the video, currently Herika has the same problem of long response time like the Matrix demo.
Of course, another issue is that playing with such a companion can burn money quickly, and this is because most of Herika&amp;rsquo;s functionality is achieved by calling paid APIs.
Still a lot of work to do before this kind of gameplay can get popular, but this mod definitely cracks open another line of bright future!&lt;/p&gt;
&lt;h2 id=&#34;ai-playing-tomb-raider&#34;&gt;AI playing Tomb Raider&lt;/h2&gt;
&lt;p&gt;OK, we&amp;rsquo;ve already seen AI controlling our companion in the game, then what&amp;rsquo;s next?
Controlling the player directly, of course!
Here is a video of AI playing Tomb Raider&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.
In this demo, similar techniques to Herika like LLM and TTS are also used.
What&amp;rsquo;s more, it seems that the author has employed several other AI modules, too, such as object detection.
It&amp;rsquo;s not yet clear how the game character is controlled at the time of writing this blog (08/13/2023).&lt;/p&gt;
&lt;h2 id=&#34;more-work-of-ai-playing-games-in-academia&#34;&gt;More work of AI playing games, in academia&lt;/h2&gt;
&lt;p&gt;It worths noting that using modern AI&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; to play games is not new.
Many previous endeavours have already been made, such as the OpenAI Five&lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt; playing Dota 2.
Many scientific experiments in the RL field were actually conducted on game environments like OpenAI Gym&lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt; and Unity ML-Agents&lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.
However, the research characteristic of this line of work makes it far from revolutionizing the gaming industry, and indeed, this was usually not the indention of researchers.&lt;/p&gt;


















&lt;figure  id=&#34;figure-an-example-of-openai-gym&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;An example of OpenAI Gym.&#34;
           src=&#34;https://shaojiejiang.github.io/post/en/ai-gaming-era/figures/openai-gym.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      An example of OpenAI Gym.
    &lt;/figcaption&gt;&lt;/figure&gt;



















&lt;figure  id=&#34;figure-an-example-of-ml-agents&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;An example of ML-Agents.&#34; srcset=&#34;
               /post/en/ai-gaming-era/figures/ml-agents_hud75644e00942eb99ca4ae5a1121fcdf2_44544_5b753ca6463c4352b20c3c6d4160653f.webp 400w,
               /post/en/ai-gaming-era/figures/ml-agents_hud75644e00942eb99ca4ae5a1121fcdf2_44544_192e35e39d2b75df501a70ef62b5bd4f.webp 760w,
               /post/en/ai-gaming-era/figures/ml-agents_hud75644e00942eb99ca4ae5a1121fcdf2_44544_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://shaojiejiang.github.io/post/en/ai-gaming-era/figures/ml-agents_hud75644e00942eb99ca4ae5a1121fcdf2_44544_5b753ca6463c4352b20c3c6d4160653f.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      An example of ML-Agents.
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;In the recent months, several other research outcomes related to gaming have attracted people&amp;rsquo;s attention, e.g., Generative Agents&lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt; by Stanford University, and CALM&lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt; by Nvidia.
While Generative Agents might have put more focus on studying human behaviour instead of game playing, CALM presents an algorithms of controlling game characters using textual commands (hence easily with voice through ASR).
What&amp;rsquo;s more interesting about CALM is that the model size it uses to control the game character is as small as several hundreds of parameters, making it easily runnable locally.
Of course, attaching LMs for more flexible natural language understanding can increase the parameter size many times, but still possible to find a good middle ground between performance and latency.&lt;/p&gt;
&lt;h2 id=&#34;outlook&#34;&gt;Outlook&lt;/h2&gt;
&lt;p&gt;It seems that the technologies for applying modern AI in games are already maturing.
Although current AI models, especially those generative ones, are often criticised for problems like hallucination, repetition, and unsafe responses etc., I would argue that such problems will be much less destructive in the game world than in real life.
It would be very interesting to see more and more games with AI companions that chat with you, and give you a hand when asked.
To make it more exciting, how about train your AI companions by yourselves, while you&amp;rsquo;re playing the game?
You already generate a lot of (labelled) data when you play games, and using it to train your AI companion is theoretically possible.
However, popular game engines like Unity and Unreal don&amp;rsquo;t directly support AI training yet, so we still need some time to make it happen.
But games with custom engines is much more flexible, and Human-Like is such a game that collects your data in the game and trains an AI opponent online.&lt;/p&gt;
&lt;p&gt;Taking a step back, not too long ago deep learning and gaming were still almost two extremes of the spectrum: the former is often associated with hard-working researchers, while the latter often reminded us of people killing time.
Gamers are usually those young and smart people, who devoted large amount of time and energy in the game they love.
Since finally the &amp;ldquo;two extremes&amp;rdquo; are coming together, maybe something more profound can happen?
Just some personal thoughts, probably unrealistic, but for instance using LLMs as portals that make the player more interested in real world, and even learn about practical skills that they can use in real life?
It might be possible, who knows?&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.replicastudios.com/blog/smart-npc-plugin-release&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Replica Smart NPCs&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=SbzBTp_kBIk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AI-Powered NPCs: A Game-Changing FREE Demo&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://aidungeon.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AI Dungeon: A text-based adventure-story game you direct (and star in) while the AI brings it to life.&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nexusmods.com/skyrimspecialedition/mods/89931&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Herika - The ChatGPT Companion&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0svu8WBzeQM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The AI Takes Control of the adventure in Skyrim!&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0wTf_bbkW2U&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Creating a Self-Aware Lara Croft that Plays Tomb Raider&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;
&lt;p&gt;As opposed to traditional AI used in games, which are usually implemented with sets of rules, here by modern AI I mean those powered by DL and/or RL algorithms&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/OpenAI_Five&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAI Five&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.paperspace.com/getting-started-with-openai-gym/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Getting Started With OpenAI Gym: The Basic Building Blocks&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://unity.com/products/machine-learning-agents&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unity Machine Learning Agents&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/joonspk-research/generative_agents&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Generative Agents: Interactive Simulacra of Human Behavior&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://research.nvidia.com/labs/par/calm/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CALM: Conditional Adversarial Latent Models for Directable Virtual Characters&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>One source of LLM hallucination is exposure bias</title>
      <link>https://shaojiejiang.github.io/post/en/llm-hallucination/</link>
      <pubDate>Wed, 09 Aug 2023 22:16:30 +0200</pubDate>
      <guid>https://shaojiejiang.github.io/post/en/llm-hallucination/</guid>
      <description>&lt;p&gt;With the release of closed-source ChatGPT, GPT-4, and open-source LLaMa models, the LLM development has seen tremendous improvements in recent months.
While we are hyped with the fact that these LLMs are capable of many tasks, we have also noticed again and again that these LLMs hallucinate content.
Today I came accross this inspiring paper, &lt;a href=&#34;https://arxiv.org/abs/2305.14552&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sources of Hallucination by Large Language Models on Inference Tasks&lt;/a&gt; by McKenna et al., in which the authors have identified two main sources of hallucination:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Knowledge that was memorised by the model during pre-training&lt;/li&gt;
&lt;li&gt;Corpus-based heuristics such as term frequency&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In my opinion, I would put these two reasons into one category: the exposure bias.
This is becuase either the memorised knowledge, or frequent terms, were exposed to the LLM at pre-training state.
The observation made in this paper is very enlightning, and reminded me of an ealier paper of mine, where we also concluded that the low-diversity issue of generative chatbots are caused by frequent terms in the training corpora&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Although LLMs are becoming larger, trained with more sophisticated techniques like RLHF, they have a deep root in the field of statistical models.
Losses are calculated based on terms, which are used to update the model weights, so it&amp;rsquo;s not surprising at all if the trained LLMs respond differently to terms with different frequencies.
And in fact, it would be surprising if these LLMs only learn &lt;strong&gt;perfect&lt;/strong&gt; grammar and semantics and totally shake off the frequency part.
There is nothing wrong for LLMs being statistical.
We human often make decisions based on experience, and isn&amp;rsquo;t that a kind of statistical model?
To make matters even worse, natural languages have a statistical nature too &amp;ndash; most of them, if not all, evolve over time, not neccessarily changing the meaning of words, but definitely changing the frequency speakers use them.&lt;/p&gt;
&lt;p&gt;As pointed out by Konstantine Arkoudas&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, GPT-4 can&amp;rsquo;t reason.
I agree with this statement.
I think LLMs are sophisticated statistical models, and the generation process is more like information retrieval but using the neural network weights and in the granularity of tokens.
Also as mentioned by Arkoudas, the lack of reasoning in LLMs has a connection with the hallucination problem.
I agree with him and many other researchers, retrieval-augmentation could serve as the &amp;ldquo;guardrail&amp;rdquo; of LLM generations, but unlikely to be the silver bullet for eliminating the hallucination problem.&lt;/p&gt;
&lt;p&gt;However, &amp;ldquo;can&amp;rsquo;t be solved&amp;rdquo; is different from &amp;ldquo;can&amp;rsquo;t be improved&amp;rdquo;.
Given that more and more studies have shown the vulnerability of LLMs to the statistical nature of their training data, maybe more effort is needed in thinking of a different way of training the model.&lt;/p&gt;
&lt;p&gt;Lastly, it&amp;rsquo;s worth noting that the McKenna et al. work was studied under NLI.
Although the hallucination problem is more prominent in NLG, it&amp;rsquo;s not straightforwad how to do a similar analysis in the NLG scenario.
But if it can be done, it would be more attention catching.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3308558.3313415&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Improving Neural Response Diversity with Frequency-Aware Cross-Entropy Loss&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.preprints.org/manuscript/202308.0148/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPT-4 Can&amp;rsquo;t Reason&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>

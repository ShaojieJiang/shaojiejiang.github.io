[{"authors":["admin"],"categories":null,"content":"I am a 2nd year PhD student under the supervision of Maarten de Rijke and Christof Monz at ILPS, University of Amsterdam. I am interested in ML and NLP, especially open-domain dialogue systems (chatbots ðŸ¤–). I also take photos as a hobby ðŸ“¸.\n","date":1560988800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1564488234,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://shaojiejiang.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a 2nd year PhD student under the supervision of Maarten de Rijke and Christof Monz at ILPS, University of Amsterdam. I am interested in ML and NLP, especially open-domain dialogue systems (chatbots ðŸ¤–). I also take photos as a hobby ðŸ“¸.","tags":null,"title":"Shaojie Jiang","type":"authors"},{"authors":["Shaojie Jiang"],"categories":["NLP","Deep Learning"],"content":" R.I.P BERT BERT got a head shot yesterday, by another guy called XLNet. It is reported that XLNet defeated BERT on 20 NLP tasks, and achieved 18 new state-of-the-art results. Isn\u0026rsquo;t it impressive? So, farewell, BERT.    R.I.P BERT   Is BERT really dead? Since I love BERT, I decided to read the paper to find out what killed him. While reading, I was thinking wait a minute, is BERT really dead? After finished the paper, I was so glad to know that BERT is still well alive! He is just wearing another coat named Two-Stream Self-Attention (TSSA), with some other gadgets! Because:\nXLNet = BERT + TSSA + bidirectional data input\nBert you\u0026rsquo;re so tough, buddy!\nLet\u0026rsquo;s take a closer look at what were trying to kill BERT.\nTwo-stream self-attention (TSSA) Why TSSA is needed to kill BERT? Well, let\u0026rsquo;s first see some weaknesses BERT has.\nBERT is using a masked language model (MLM) training objective, which is essentially why it achieves bidirectional representation.    Image source   In this example, both words \u0026ldquo;store\u0026rdquo; and \u0026ldquo;gallon\u0026rdquo; are intended to be predicted by BERT, and their input word embeddings are replaced by the embedding of a special token [MASK]. Usually this isn\u0026rsquo;t a problem, but what if the prediction of \u0026ldquo;store\u0026rdquo; requires knowing the word \u0026ldquo;gallon\u0026rdquo;? That is exactly where BERT falls short.\nTSSA is what you can use to overcome that downside of MLM:    Query stream, source   In this illustration, query stream gives you the query vector needed for attention calculation, and this stream is designed in such a way that it doesn\u0026rsquo;t leak the info of the word it\u0026rsquo;s going to predict, but guarantees all information from other positions. Take $x_1$ for example: $x_1$\u0026rsquo;s embedding (and hidden state) is not used at all, but embeddings and hidden states from other positions are used in each layer.\n   Content stream, source   Content stream, on the other hand, gives you the key and value vectors needed for context vector calculation. This stream uses a strategy similar to that in a standard Transformer decoder by masking future positions. The only difference is that in content stream, the order of tokens is randomly permuted. For example $x_2$ is right after $x_3$, and therefore $h_2^{(1)}$ can only see the embedding of itself and that of $x_3$ (and $mem^{(0)}$), but not that of $x_1$ or $x_4$.\nMask a span Another difference from BERT is masking a span of consecutive words. The reason I guess, is that this guarantees the dependence of masked words (as claimed to be what BERT can\u0026rsquo;t model). This is not a fresh-new idea, though. Recently there are two ERNIE papers (BERT based) that propose masking named entities (often of multiple words, paper link) and/or phrases (paper link).\nBidirectional data input Another notably different thing in XLNet is the usage of bidirectional data input. The idea (I guess) is to decide the factorization direction (either forward or backward), so that the idea of \u0026ldquo;masking future positions\u0026rdquo; used in a standard Transformer decoder can also be easily used together with XLNet.\nMasking a span makes XLNet look like a denoising autoencoder; but by using bidirectional data input (or masking future positions), XLNet performs more like a autoregressive language model in the masked region.\nClosing remarks So now you probably can see the similarities and differences between XLNet and BERT. If not, here is a quick summary:\n Instead of masking random words, mask a span of words Use bidirectional data input to decide which direction you treat as \u0026ldquo;future\u0026rdquo;, and then apply the idea of masking future positions To avoid leaking the information of the position to be predicted, use Two-Stream Self-Attention (TSSA) Other minor things like segment recurrence, relative positional encoding, etc.  However, it doesn\u0026rsquo;t seem to be enough changes to make all those improvements. What if BERT is also trained using the additional data (Giga5, ClueWeb, Common Crawl), will XLNet still be able to defeat BERT?\nEDIT:\n Another model named MASS employs a very similar idea. According to Jacob Devlin (author of BERT), relative positional embedding might be of great importance.  ","date":1560988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562249246,"objectID":"062f3b0d22289906f49ec859d89f3c3c","permalink":"https://shaojiejiang.github.io/post/xlnet/","publishdate":"2019-06-20T00:00:00Z","relpermalink":"/post/xlnet/","section":"post","summary":"In this post, I will try to understand what makes XLNet better than BERT.","tags":["BERT","Transformer","XLNet"],"title":"What's New in XLNet?","type":"post"},{"authors":["Shaojie Jiang","Pengjie Ren","Christof Monz","Maarten de Rijke"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562163860,"objectID":"b3a4e5ab9d577302864b0f9fed964dea","permalink":"https://shaojiejiang.github.io/publication/jiang-2019-improving/","publishdate":"2019-07-03T14:11:43.236784Z","relpermalink":"/publication/jiang-2019-improving/","section":"publication","summary":"","tags":["Chatbot","Dialogue system","Sequence-to-sequence model"],"title":"Improving Neural Response Diversity with Frequency-Aware Cross-Entropy Loss","type":"publication"},{"authors":["Shaojie Jiang","Maarten de Rijke"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562163860,"objectID":"efb8b2e27e980d0e5fc82c2aeb85ada0","permalink":"https://shaojiejiang.github.io/publication/jiang-2018-sequence/","publishdate":"2019-07-03T14:11:43.236107Z","relpermalink":"/publication/jiang-2018-sequence/","section":"publication","summary":"","tags":null,"title":"Why are Sequence-to-Sequence Models So Dull? Understanding the Low-Diversity Problem of Chatbots","type":"publication"},{"authors":["Shaojie Jiang","Jifeng Ning","Cheng Cai","Yunsong Li"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562163860,"objectID":"78279d46cb00b734ed5b0a0e62a5ece1","permalink":"https://shaojiejiang.github.io/publication/jiang-2017-robust/","publishdate":"2019-07-03T14:11:43.237507Z","relpermalink":"/publication/jiang-2017-robust/","section":"publication","summary":"","tags":null,"title":"Robust Struck tracker via color Haar-like feature and selective updating","type":"publication"},{"authors":["Jifeng Ning","Jimei Yang","Shaojie Jiang","Lei Zhang","Ming-Hsuan Yang"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562163860,"objectID":"9c2efa257f5582fd9c1a59c4dbed5c4d","permalink":"https://shaojiejiang.github.io/publication/ning-2016-object/","publishdate":"2019-07-03T14:11:43.235175Z","relpermalink":"/publication/ning-2016-object/","section":"publication","summary":"","tags":null,"title":"Object tracking via dual linear structured SVM and explicit feature map","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562172382,"objectID":"fd36605688ef45e10dc233c860158012","permalink":"https://shaojiejiang.github.io/cv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/cv/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I am a Senior Machine Learning Scientist at Huawei R\u0026amp;D Center Amsterdam. I work on training Huawei’s ChatGPT models, and am responsible for the Reinforcement Learning algorithm development and model training. More broadly, my work involves chatbots, information retrieval and conversational QA systems. In parallel, I am completing my PhD at the University of Amsterdam, under the supervision of Prof. Maarten de Rijke. In the past, I did two internships at Replika.ai and Amazon.com, respectively.\nDownload my CV in PDF\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1691615358,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Senior Machine Learning Scientist at Huawei R\u0026D Center Amsterdam. I work on training Huawei’s ChatGPT models, and am responsible for the Reinforcement Learning algorithm development and model training.","tags":null,"title":"Shaojie Jiang","type":"authors"},{"authors":null,"categories":null,"content":"我是一个在阿姆斯特丹大学读书的计算机博士生，主要研究方向是自然语言处理和深度学习/人工智能。 英文版主页分享所有我学术相关的内容，中文版主要用于分享一些课外阅读相关的笔记、兴趣爱好、碎碎念等短博客。\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1637840324,"objectID":"d19cb99606c79129dc5815cfb5145ebb","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"我是一个在阿姆斯特丹大学读书的计算机博士生，主要研究方向是自然语言处理和深度学习/人工智能。 英文版主页分享所有我学术相关的内容，中文版主要用于分享一些课外阅读相关的笔记、兴趣爱好、碎碎念等短博客。","tags":null,"title":"江少杰","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650770445,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://shaojiejiang.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Shaojie Jiang"],"categories":["personal notes","creativity training","ideas"],"content":"Generative models of all kinds of modalities, including textual, image, and audio, are evolving very fast. They have started to replace humans in some labor-intensive scenarios, and they will keep doing so. Like many others, I believe this is a good trend in the long run. It’s very similar to the Industrial Revolution when much human labor was replaced by machines. Yes, it will cause some short-term turbulence. But look at the colorful clothes normal people on the street are wearing now, which were privileges of the higher classes a couple of centuries ago. How could we have achieved this without the Industrial Revolution? I believe we can expect an even more “colorful” future with AIGC technologies.\nGenerative models are like pens, brushes, and dictionaries, which serve to boost our productivity. Why is that? In the past, without pens or dictionaries, it was difficult for many people to read, write, or paint well; in the future, with the help of generative models, more and more people will be able to write and paint decently. And this to me, sounds like a liberation for humanity.\nBut tools are just tools. They can make you more productive but don’t necessarily make you more creative. I believe with the liberated productivity, we humans will and should devote more time to being creative.\nAs a practice for myself, I open this blog to keep track of some of my ideas. They are not brilliant ideas, and probably many of them sound stupid and funny, but I would like to see some of them come true because I believe they can help make the world a better place. Maybe some of them already exist in a corner I don’t know yet. If I come across them in the future, I’ll come back and add pointers to them.\nI first started this exercise in my notes and thought that I was going to realize them at some point. Slowly, I came to feel that I wouldn’t be able to work on most of them, so why don’t I make them public? If they can be useful of any sort, that’s the best I want to see. But probably most of these ideas just don’t make much sense, and in that case, I hope you can still have some fun reading it. I also welcome everyone to join me for brainstorming new ideas, as an exercise. Just keep practicing, and who knows one day we won’t come up with a brilliant idea that can influence the world?\nUsing video game addiction for good causes Video game addiction has been a concerning social problem for years. However, I’m afraid this is only going to get worse with the climbing unemployment rates – a lesson learned from the Hollywood growth during the Great Depression. The game addiction problem should receive more attention, especially because addicts are usually juveniles and young adults – the group of people who have the most potential.\nAlthough new, responsible careers have been developed around the video game industry, and even the Olympic Games have adopted the Esports series, it’s usually difficult to see how people’s time spent playing games is directly benefiting themselves or society. Let’s make some comparisons. Bakers and chefs feed people, bus drivers transport people, and teachers educate people. What do gamers contribute, especially when they spend too much time? That is the main reason why our parents have strong stereotypes about video games, and they do have a point.\nIs entertainment the primary nature of video games, or is it that we haven’t tried hard enough to endow them with more usefulness? I’m leaning towards the latter. It’s good to see that people from the serious games community have never stopped trying to bring values other than pure entertainment to (video) games. I can’t help but imagine what it be like if all game developers changed to work on serious games! It must be a whole new world where both education, relationships, work, and more are revolutionized. Metaverse is arguably a concept in the light of this possible future.\nJust a side note, with the stunningly fast development of AI, I tend to become a believer in the Simulation Hypothesis. Imagine that one day we can simulate everything, including all human senses and interactions with the world, it might be appealing for us to submerge the virtual reality for our development as well as that of society. And this is becoming more and more realistic.\nIn the spirit of channeling game addiction to good causes, below are some ideas that can help. If we can’t overcome game addiction, let’s make good use of it.\nShoot to label Among the top 5 most played games on Steam,1 3 are FPS games. What if we replace the players of human shapes with images that we collected from the real world, and ask the players to shoot the specified targets? For example, we collect some images of animals, in all lighting and surroundings, then we ask the players to shoot for a random type of animal in each round. In this way, we turn the FPS game into a labeling task! The images receive more bullets and are treated as annotated with higher quality. We can even mix in some “golden …","date":1695488144,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695570721,"objectID":"ec996d6c1831a495d3e7c6cbdf1d017b","permalink":"https://shaojiejiang.github.io/post/en/creativity-training/","publishdate":"2023-09-23T18:55:44+02:00","relpermalink":"/post/en/creativity-training/","section":"post","summary":"AI models like LLMs will keep replacing human labor. But they are just tools, we could and should win them in creativity! I already started my training.","tags":["personal notes","creativity training","ideas"],"title":"Notes for Creativity Training","type":"post"},{"authors":["Shaojie Jiang"],"categories":["responsible AI","personal opinions"],"content":"I have received several job invitations from the adult industry. They said they are in a blooming market with the popularity of LLMs and chatbots, which I have no doubt. They all also mentioned Replika in our chats, which was not surprising at all – I did an internship there in 2021, and they had already worked on sexting for years.\nMy pitch Since this is kind of a sensitive topic, I think it’s important to set the pitch first.\nAlthough I have received higher education, I don’t despise at all the legitimate adult industry. Although I’m from a country that is very famous for its strictness over the adult industry, I have no prejudice over sex-related work, thanks to my experience in NL, Amsterdam especially. Business is business. I respect every profession as long as they are legal and ethical. Sex is part of human nature, so many professions around it are ethical in the right context. I respect sex-related workers even further if they donate part of their (expectedly high) profit to social good. I interned at Replika, but my work was not related to the erotic part. I have no intention of stepping into this industry yet, and the reason is that it’s not the time yet. As you see from the teaser image, I adapted the catchword a bit, which suits my lifelong mission perfectly: I want to cleverly die as a responsible adult. Please hear me out.\nMy story with Replika When I started my internship at Replika, I didn’t know that the company was working on erotic roleplay. I received the offer because of two reasons:\nThe perfect match with my PhD research topic Its emotional-support aspect, which I think Replika has been doing a decent job In my opinion, Replika has been a very responsible company. They separated very well the subscribe-only, erotic part from the free, normal, and emotional support part. Besides, they were happy that some users used their app to learn English. What more can you expect from a for-profit company/startup? They charge nothing for the part they influence society positively; they deepen the emotional support part further for people who are suffering from the lack of intimate relationships. Agreeably, having both adult and children-safe content in the same app can pose some harm to juveniles.1 But dangerous as adult content to children as fire and blade, are everywhere in life. It’s the responsibility of many parties to protect juveniles from such harmful things. Besides, Replika is working on separating the erotic part,2 which in my opinion is another responsible action/response.\nWhy do I think it’s not the right time for me to do adult business? The short answer is that my value can be better utilized in a way more beneficial to society. Going against the prosperity of the LLMs and chatbots, my team at Huawei working on the exact topic is experiencing adversity. This offered me a chance to reconsider the value of my work on a broader scope: how did I perform responsibly as an Earth citizen? Although I believe Huawei is in general a responsible and honorable company, it doesn’t mean that every division of it is responsible. My work more specifically, hasn’t had much chance to carry out its responsibility towards the social good. I need a recalibration of my compass, therefore, I wouldn’t accept any distraction to my long-term goal: social responsibility.\nWhat I would be happy to see? Neither am I ready to devote myself to the adult business nor is the business ready for me, it seems. I would definitely be happy to contribute my knowledge and experience in the following aspects of the adult business:\nFight human trafficking and abusing Anti-harassment Privacy protection Anti addiction Etc. If you’re such a team, I’ll highly appreciate it if you reach out to me. I’m a believer in compounding power: a good deed, be it small, can have an overturning effect with enough time. Some other related industries I’m passionate about are:\nEducational games, so that we can help channel game-addiction into the addiction to something that brings real value to the world Healthcare, which might lead to a future of chatbots saving lives every day, which is already happening3 I want to elaborate a bit more on the anti-addiction part. There are many bad examples in real life other than sex-related addiction. Here I want to mention some products that are creating new, unhealthy addictions, such as YouTube and TikTok. Interestingly, if you search Google with the keywords “TikTok’s effort in fighting addiction”, you will see a lot of articles on using TikTok for fighting substance addiction, but you won’t see ANY of TikTok’s effort in dealing with addiction to its own app. I’m not happy with the finding, especially given the context that my parents, together with many friends and relatives, are TikTok addicts. Yet these companies have spent little to no effort in fighting the unhealthy addiction they caused.\nGoogle results of “TikTok’s effort in fighting addiction” I have a dream Here is how I want the world to …","date":1695232987,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695803302,"objectID":"6759b1a50395b735983659ef7a329649","permalink":"https://shaojiejiang.github.io/post/en/responsible-aigac/","publishdate":"2023-09-20T20:03:07+02:00","relpermalink":"/post/en/responsible-aigac/","section":"post","summary":"AIGAC (AI-generated adult content) is becoming a thing. What should come together is the Responsible-AIGAC.","tags":["responsible AI","personal opinions"],"title":"Job Invitations From Adult Industry Are Welcome, but Not in the Way You Are Thinking Of","type":"post"},{"authors":["江少杰"],"categories":["教育","时事","个人观点"],"content":"(English version can be found here)\n我带着愤怒开始写这篇博客。如果学校只是一个勾勒出我们能做什么的地方，那么学校和监狱又有何区别呢？\n令我震惊的消息 我的外甥吉米于2023年9月1日刚上小学，在天津市一个郊区的学校。他不是一个很外向的孩子。如果我们几个月没见面，再见面时他会害羞得说不出话来，即使几天前我们还在电话中愉快地聊天。我安慰自己：“对于一个内向的孩子来说，害怕上学是正常的。”“他很快就能适应。”\n新学期开始几天后，我碰巧有机会去看他。然而，当我看到他对学校多么抵触的时候，我意识到这不仅仅是他的年龄小或内向的原因。每次他要上学时，他都会哭诉：“学校太无聊了，”“时间过得太慢”这样的话。我能理解，中国的学校并不是一个总是很有趣的地方。但是“时间过得太慢”这句话引起了我的注意：他还是一个6岁的孩子，怎么可能感到时间过得太慢呢？如果他玩得开心，他应该觉得时光飞逝才对。我感觉有些不对劲，于是我决定调查一下。\n我首先问他为什么不喜欢学校，难道学校不是有很多有趣的地方吗？我回忆起自己在小学玩课间玩游戏的快乐记忆。那是上世纪90年代中期，我生活在中国一个非常落后的小镇。我们没有太多的玩具可以玩，所以我们好好发挥了自己的创造力：我们玩各种互动游戏，比如捉迷藏、警察抓小偷；我们还充分利用身边能找到的材料，折纸飞机、玩摔四角（见下文）、拔老根儿（见下文）。还有很多其他的有趣的活动。我不敢说自己总体上喜欢小学时光，但想起这些游戏，笑容仍会爬到我的脸上。我问外甥你们现在没有类似的活动可以玩吗？\n摔四角 注：摔四角游戏是一种将纸折成方块的竞技游戏。在游戏中，玩家轮流在地上、对手的方格上或者旁边摔自己的四角。如果能打翻对手的四角，你就赢得本轮并且赢走对手的四角。玩四角厉害的可以在一个赛季赢下厚厚一摞。\n拔老根儿 注：拔老根儿通常用树叶梗或者草棒进行比赛。像上图那样，以扯断对方的老根儿为乐。这跟大男孩们喜欢的MMA有异曲同工之妙——你要么一直赢下去，要么就报废。\n当我听到他们课间不让自由活动时，我感到非常震惊。他们课间必须呆在教室里，除非需要喝水或上厕所。是的，你没看错。不能在走廊里追逐打闹，更别提去操场上玩。感到难以理解，我建议他带上智能手表去上学，这样我可以在课间休息时给他打个视频电话，直观感受一下他们课间大家是个什么状态。但我发现智能手表在他入学的第一天就被禁了。我继续鼓励他，建议他带一些玩具，这样他至少可以开心一些。但是很抱歉，玩具当然也是被禁止的。\n我仍然没有放弃，开始向我的朋友和亲戚们打听，希望吉米的学校只是个案。很快我得到了一些回复。有几个亲戚说这件事很常见，而且在北京情况更严重。另一个朋友，现在是我老家一所小学的老师，表示这就像COVID-19一样——已经成了新常态。嗯，现在我需要有人来鼓励我了。\n体育课 绝望之外，一丝丝的慰藉是吉米每周四天有体育课。 此外，在每天早上30分钟的大课间里，他们会做广播体操。 这是每天唯一一次允许他们在操场和校园里活动的时间。 我和我姐姐决定对这些户外活动的质量进行一些调查。 我们也满怀乐观地认为，在广播体操之后，学生们可能有机会在户外自由玩耍一会儿。 然而，现实让我们再次感到惊讶。\n下面是我在体操结束后拍摄的一段视频。 孩子们被有序地带回教室。 在校园的另一个角落里，一位老师训诫她的学生：“进入走廊之后不要说话。迅速喝点上厕所。不要让我重复！”\n第二段视频记录了他们在体育课上进行的“非常激烈”的体育活动。 他们在40分钟的时间里走了整整三圈，这解释了为什么他们在不走路的时候需要一直好好地休息。 哦对了，他们其他时间还在练习怎么站队，旁边的二年级或者更高年级（因为他们已经有校服了）也是整节课都在打磨队伍的整齐性。 原因 你可能觉得这是COVID-19规定的副产品，就像我一开始所认为的那样。整个社会在那痛苦的3年多里基本上都受到了这种教育，所以学校仍然活在担心爆发新一轮疫情的阴影之下。但是我的老师朋友给我讲了一个真实的故事，让我对背后的原因有了更好的理解。一个男孩的父母因为孩子在学校摔了一跤，导致他的一颗牙上磕掉了跳蚤大小那么一块。家长对学校不依不饶，给学校施压数月，要求学校找到一个令他们满意的解决方案。他们最终成功了。你可能会想：“家长怎么会对学校造成这么大的压力？”你看，现在有各种各样的社交媒体，在已经发生的无数个故事里，父母们通过向媒体曝光或者向教育局投诉来“揭露”学校的“疏忽”（可能你上面摔跤那样学校完全没有责任）。你可能会觉得教育局会主持公道，但更简单的解决办法就是把压力传回给学校，让学校解决他们自己的问题。教育局应该也是这样认为的，所以通常情况下这类事情都这样结束。\n思考和诉求 在我询问的朋友中，有一个在深圳一所小学当老师的朋友说他们学校仍然有正常的课间休息。孩子们可以自由地活动。但在她之前给我讲过的另一个令我震惊的故事里，一位老师不得不给一个学生下跪来求他不要退学。现在我对情况有了更深入的了解，我对学校和老师们感到同情。\n然而，我不认为学校是无辜的。恰恰相反，我认为学校对当前的状况负有最大的责任，尽管我认为根本原因是不理性的父母、失职的教育局和社交媒体的滥用。以下是我的理由。在我看来，尽管教育体系包括家庭、学校和社会，但学校在这三方中是主导者。它们是学生度过大部分学习时间的地方，也是大多数跟学生相关的现象（好的或坏的）开始的地方。在不好现象出现后，学校应该承担纠正它们的责任，以防事情继续恶化。学校和教师不能坐视教育体系走向毁灭，不是吗？\n家长们以及对这个社会仍然有信心的公民们也不应该对这些负面趋势坐视不管。即使我们难以在短期改变这种情况，我们也应该继续奋斗。媒体，尤其是传统媒体，你们是这个社会的耳目和喉舌，请不要假装一切都正常，更不要被社会的丑陋当枪使。\n教育局，你们是教育体系的大脑。你们最有权力，但请记住，权力越大责任越大。如果你们睡着了，请醒一醒。如果你们喝醉了，请在工作时间保持清醒。也许你们仅仅是过载了，那么请重新考虑是否承担了太多不必要的责任。不要忘记在人体中，大脑不是整个神经系统，尽管它是神经系统的核心。管理的艺术在于把责任与权利一起分配下去。\n结语 在吉米所在学校一墙之隔的初中部，也是做完课间操就回教学楼，课间也不见有人在外活动。 如果这种现象持续下去，甚至扩大开来，我可以想象几年后的大学也会采纳同样的规定。 他们没有理由不这样做：学校和大学需要处理的麻烦将大大减少；学生们如此和乖巧守规矩。 当他们开始走向工作时，雇主们也会为他们下属的言听计从而感到十分高兴。 很快，在未来的病毒爆发中，人们将被舒服地享受封锁生活，他们将感觉比他们父母一代的人轻松千万倍。\n","date":1695224460,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695281807,"objectID":"fb520d4960965e79374f9b1a241af03e","permalink":"https://shaojiejiang.github.io/post/zh/school-problems-china/","publishdate":"2023-09-20T17:41:00+02:00","relpermalink":"/post/zh/school-problems-china/","section":"post","summary":"如果学校只是一个勾勒出我们能做什么的地方，那么学校和监狱又有何区别呢？","tags":["教育","时事","个人观点"],"title":"学生课间不允许自由活动，然后呢？","type":"post"},{"authors":["Shaojie Jiang"],"categories":["education","current affairs","personal opinions"],"content":"（中文版请点击这里）\nI started this post with anger. If school is a place that only outlines what we CAN do, then what are the differences between schools and prisons?\nThe shocking news My nephew Jimmy just enrolled in primary school on September 1, 2023, in a suburban district of Tianjin, China. He isn’t a very extrinsic kid. He would even be too shy to talk with me after being separated for a couple of months, even if we had just talked happily on the phone days ago. “It’s natural for an intrinsic kid to be afraid of school.” I comforted myself, “He’ll get through it soon.”\nSeveral days after the new semester, I happened to have an opportunity to visit him. However, when I saw how resistant he was to school, I realized it was more than his young age or intrinsic characteristics. He had been crying every time he set for school, repeating things like “it’s too boring,” and “time goes too slow.” Yeah, I can relate to my old memory, Chinese schools weren’t necessarily interesting places. But the words “time goes too slow” rang my bell: he is just a 6-year-old, how would he have the feeling of time being too slow?? If he was enjoying, he should have felt time flies. I sensed something was wrong and decided to investigate.\nI started by asking him why he didn’t like school while he had so much fun to enjoy, recalling the happy memory I had in primary school playing games between classes. It was the mid-1990s, in a very underdeveloped town in China. We didn’t have as many toys to kill time, so we made good use of our creativity: we played all kinds of interactive games, like hide-and-seek, police chasing suspects; we also made good use of materials we found nearby, flying paper planes, square-bashing competition (read on for explanation), stalk-pulling (see below). The list goes on and on. I wouldn’t say I enjoyed my primary school overall, but remembering those games, I still can’t resist putting on smiles. I asked my nephew weren’t these fun activities to do at school?\nThe Square-bashing Game. Note: The square-bashing game is a game with papers folded into squares. In the gameplay, players bash their squares in turn on the ground, nearby, or on their opponents’ squares. If the opponents’ squares flip, you win their squares. A good player is proud of piling up the squares he wins – triumphs to show others how powerful he is.\nThe Game of Stalk-pulling. Note: The stalk-pulling game is played by pulling stalks (usually from fallen tree leaves) as illustrated above. The one whose stalk breaks loses the game. The fun is very similar to the big boys game, MMA – you keep winning or you’re done.\nI was shocked to hear that they are not allowed to enjoy the break-time anymore. They must remain in the classroom unless they need to get water or use the toilet. Yes, you read it right. No chasing around in the corridor, not to mention in the schoolyard. Feeling too hard to comprehend, I asked him to wear his smartwatch to school, so that I could give him a video call during break-time and observe his environment by myself. Only to know that smartwatches were said to be banned on the first day of his admission. Trying to cheer him up, I suggested taking some toys so that he could at least have some fun. But sorry, toys are banned too, of course.\nStill not giving up, I started asking around my friends and relatives, with the hope that Jimmy’s school was just a special case. Soon I got some responses. Some relatives said this to be very common, and even more serious in Beijing. Another friend, who is now a teacher in a primary school in my hometown, expressed that this is just like COVID-19 – a new norm. Now I need somebody to cheer me up.\nPE classes Beside the hopelessness, a very slight comfort is that Jimmy has a PE class 4 days a week. They also have group gymnastics every day during the long, 30-minute break in the morning. These are the only times when they are allowed in the schoolyard and the playground. My sister and I decided to do some investigation on the quality of such outdoor activities. We also optimistically thought that after the group gymnastics, the students might have the chance to play freely. Yet we were surprised again.\nBelow is a video I took after the gymnastics. Kids were taken back to the classroom in order. In another corner of the schoolyard, one teacher instructed her students: “Don’t talk while in the corridor. Quickly drink some water and use the toilet if needed. Don’t make me repeat!”\nThis second video witnessed the “very fierce” sport they did during the PE class. They walked for three whole rounds during the 40-minute class, which explains why they needed to have good rest when they weren’t walking. Oh right, they also spend quite some time in practicing lining up the troop. Another class nearby, 2nd grade or even higher (because they have uniforms already), also spent their whole class in practicing the lining. The reason You may tend to think this is a byproduct of the COVID-19 regulations, as I did …","date":1694404704,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695570260,"objectID":"f435613784c1a0c56f101fc32b072c34","permalink":"https://shaojiejiang.github.io/post/en/school-problems-china/","publishdate":"2023-09-11T11:58:24+08:00","relpermalink":"/post/en/school-problems-china/","section":"post","summary":"If school is a place that only outlines what we CAN do, then what are the differences between schools and prisons?","tags":["education","current affairs","personal opinions"],"title":"Break Time Banned in Chinese Schools. What Now?","type":"post"},{"authors":["Shaojie Jiang"],"categories":["Deep Learning","NLP","LLM","video games"],"content":"With the big noises made by ChatGPT, many different industries have noticed the value of LLM technologies. Unsurprisingly, the video game industry is one of them. In this blog, I introduce several cool demos/WIPs that I’ve recently found, and share my opinions on why they might have profound influences on the future of video game industry. I also try to explain the current difficulties, and possible directions for solving them. In the end, I also share some dreams of future games. I believe, the era of AI has come to video games!\nThe Matrix AI-Powered NPCs demo by the Replica Studios Players are used to have chats with the NPCs, but most of these conversations are scripted. The current best conversational experience you can have with NPCs is to select from several possible responses, so you have some freedom of steering dialogues.\nDialogue selection in Witcher 3 If you are a game lover, have you ever dreamt about talking to NPCs like they’re other human players? Well, this is definitely possible now, and the Replica Studios already made a demo about it1. Instead of looping over pre-scripted lines, the Replica Studios attached LMs (probably OpenAI ChatGPT) to the NPCs, allowing them to all speak characteristically. You can even chat with NPCs using your voices directly, and they will speak back. Take a look at this YouTube video2 of the demo.\nIn many games, the plot is driven (or better put, reflected) by chatting with NPCs. But since LLM chatbots can have randomness in their responses, maybe in the future, the game progression can be take to anywhere, so that every player can have a unique experience in the same game. This is already partly made true in the AI Dungeon text game3.\nThe Matrix demo may look sleek in the video, but in reality it can take around 10 seconds to get a response from NPCs. This lag is probably due to many users are calling the LLM API at the same time, and slow processing of several different modules, such as ASR and TTS. Besides, current general-purpose LLMs like ChatGPT are very large in terms of number of parameters, and this means long processing time. Potential solutions can be training bespoke, smaller-sized chatbot models, and maybe even audio-to-audio model so that the processing is simplified.\nHerika by Dwemer Dynamics The experience that every player being able to conduct unique conversations with each NPC can already be fascinating. Isn’t it more interesting to have a computer-controlled companion, one that can not only chat with you, but can also follow your voice commands? Then you definitely want to check out Herika, a mod4 for The Elder Scrolls V: Skyrim. Herika is a ChatGPT-powered AI companion that can understand the player’s audio and textual inputs. She is capable of chit-chatting with the player, commenting on the game scenes and events, following the player’s various commands, and more.\nSystem design of Herika. Image credit: Dwemer Dynamics Above is an illustration of Herika’s system design. Here is a brief overview of its main components:\nAudio inputs and outputs are processed to and from texts by ASR and TTS modules Game objects, scenes, locations, etc., are extracted from the game as texts The chatting and commenting are all achieved by querying the OpenAI API, in the form of role-playing chats Given player’s command in natural language, the command-following ability is achieved by asking GPT to generate formatted commands that are used by the game engine to control Herika Check out this YouTube video5 to get the feeling of how Herika works. Although it seems to work astonishingly well in the video, currently Herika has the same problem of long response time like the Matrix demo. Of course, another issue is that playing with such a companion can burn money quickly, and this is because most of Herika’s functionality is achieved by calling paid APIs. Still a lot of work to do before this kind of gameplay can get popular, but this mod definitely cracks open another line of bright future!\nAI playing Tomb Raider OK, we’ve already seen AI controlling our companion in the game, then what’s next? Controlling the player directly, of course! Here is a video of AI playing Tomb Raider6. In this demo, similar techniques to Herika like LLM and TTS are also used. What’s more, it seems that the author has employed several other AI modules, too, such as object detection. It’s not yet clear how the game character is controlled at the time of writing this blog (08/13/2023).\nMore work of AI playing games, in academia It worths noting that using modern AI7 to play games is not new. Many previous endeavours have already been made, such as the OpenAI Five8 playing Dota 2. Many scientific experiments in the RL field were actually conducted on game environments like OpenAI Gym9 and Unity ML-Agents10. However, the research characteristic of this line of work makes it far from revolutionizing the video game industry, and indeed, this was usually not the indention of researchers.\nAn …","date":1691939113,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692520000,"objectID":"a6a8422ed5e65bb148ac09a83f72b86e","permalink":"https://shaojiejiang.github.io/post/en/ai-gaming-era/","publishdate":"2023-08-13T17:05:13+02:00","relpermalink":"/post/en/ai-gaming-era/","section":"post","summary":"With the big noises made by ChatGPT, many different industries have noticed the value of LLM technologies. Unsurprisingly, the video game industry is one of them. In this blog, I introduce several cool demos/WIPs that I’ve recently found, and share my opinions on why they might have profound influences on the future of video game industry.","tags":[],"title":"Has the AI-Era come to video games already?","type":"post"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning","NLP","LLM","hallucination","information retrieval"],"content":"With the release of closed-source ChatGPT, GPT-4, and open-source LLaMa models, the LLM development has seen tremendous improvements in recent months. While we are hyped with the fact that these LLMs are capable of many tasks, we have also noticed again and again that these LLMs hallucinate content. Today I came accross this inspiring paper, Sources of Hallucination by Large Language Models on Inference Tasks by McKenna et al., in which the authors have identified two main sources of hallucination:\nKnowledge that was memorised by the model during pre-training Corpus-based heuristics such as term frequency In my opinion, I would put these two reasons into one category: the exposure bias. This is becuase either the memorised knowledge, or frequent terms, were exposed to the LLM at pre-training state. The observation made in this paper is very enlightning, and reminded me of an ealier paper of mine, where we also concluded that the low-diversity issue of generative chatbots are caused by frequent terms in the training corpora1.\nAlthough LLMs are becoming larger, trained with more sophisticated techniques like RLHF, they have a deep root in the field of statistical models. Losses are calculated based on terms, which are used to update the model weights, so it’s not surprising at all if the trained LLMs respond differently to terms with different frequencies. And in fact, it would be surprising if these LLMs only learn perfect grammar and semantics and totally shake off the frequency part. There is nothing wrong for LLMs being statistical. We human often make decisions based on experience, and isn’t that a kind of statistical model? To make matters even worse, natural languages have a statistical nature too – most of them, if not all, evolve over time, not neccessarily changing the meaning of words, but definitely changing the frequency speakers use them.\nAs pointed out by Konstantine Arkoudas2, GPT-4 can’t reason. I agree with this statement. I think LLMs are sophisticated statistical models, and the generation process is more like information retrieval but using the neural network weights and in the granularity of tokens. Also as mentioned by Arkoudas, the lack of reasoning in LLMs has a connection with the hallucination problem. I agree with him and many other researchers, retrieval-augmentation could serve as the “guardrail” of LLM generations, but unlikely to be the silver bullet for eliminating the hallucination problem.\nHowever, “can’t be solved” is different from “can’t be improved”. Given that more and more studies have shown the vulnerability of LLMs to the statistical nature of their training data, maybe more effort is needed in thinking of a different way of training the model.\nLastly, it’s worth noting that the McKenna et al. work was studied under NLI. Although the hallucination problem is more prominent in NLG, it’s not straightforwad how to do a similar analysis in the NLG scenario. But if it can be done, it would be more attention catching.\nImproving Neural Response Diversity with Frequency-Aware Cross-Entropy Loss ↩︎\nGPT-4 Can’t Reason ↩︎\n","date":1691612190,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691960846,"objectID":"569cfe791ff8facc7ba6ab750d4cd193","permalink":"https://shaojiejiang.github.io/post/en/llm-hallucination/","publishdate":"2023-08-09T22:16:30+02:00","relpermalink":"/post/en/llm-hallucination/","section":"post","summary":"With the release of closed-source ChatGPT, GPT-4, and open-source LLaMa models, the LLM development has seen tremendous improvements in recent months. While we are hyped with the fact that these LLMs are capable of many tasks, we have also noticed again and again that these LLMs hallucinate content.","tags":[],"title":"One source of LLM hallucination is exposure bias","type":"post"},{"authors":["Shaojie Jiang","Svitlana Vakulenko","Maarten De Rijke"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675033589,"objectID":"895e4f83fa6a3ea3215e981e618944b8","permalink":"https://shaojiejiang.github.io/publication/jiang-2023-weakly/","publishdate":"2023-01-29T23:01:57.847161Z","relpermalink":"/publication/jiang-2023-weakly/","section":"publication","summary":"","tags":null,"title":"Weakly Supervised Turn-level Engagingness Evaluator for Dialogues","type":"publication"},{"authors":["Shaojie Jiang","Ruqing Zhang","Svitlana Vakulenko","Maarten de Rijke"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675033589,"objectID":"b0dbb9b1cefeff88eec7c2da4542b791","permalink":"https://shaojiejiang.github.io/publication/jiang-2022-simple/","publishdate":"2023-01-29T22:58:29.976238Z","relpermalink":"/publication/jiang-2022-simple/","section":"publication","summary":"","tags":null,"title":"A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration","type":"publication"},{"authors":["江少杰"],"categories":["情商课"],"content":"这是非常短的一本书。作者主要分享了有求于人时的7个突破口，分别是：\n投其所好 儆其所恶 选择的自由 被认可欲 非你不可 团队化 感谢 结合之前读的《The 7 Habits of Highly Effective People》发现，这些技巧与高效能人士的办事原则并不冲突，反而是相互补充的：原则是大方向的导航，技巧是走好每一步的保障。而且经得起时间检验的技巧也都是以原则为指导的；只顾眼下利益的技巧，更应该叫“套路”，而这用不了几次就会被人识破。\n以上7个技巧分别对应了哪项做事原则呢？\n投其所好、儆其所恶，是“双赢原则”的实践 提供选择、被认可欲、非你不可，是“要想被理解，先要理解对方”原则的实践 团队化，是理解、认可对方的一种方式，更是“协同原则”的直接实践 衷心感谢，也属于对别人付出的理解和认可 另外书中提到一点“要想掌握‘措辞菜谱’，输出是最便捷的途径”，正印证了本人学习的三要素 博客里关于“输出”对于学习的重要性。\n最后吐槽下该书的不足：作者同样1为广告文案员，因此第二章（最后一章）基本都是关于文案写作的语言张力的，与情商没什么关联，有点被欺骗的感觉。作者可能犯了文案员“标题党”的职业病了吧。\n相对于上一本书《好文案一句话就够了》的作者 ↩︎\n","date":1593520676,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"116a11027a095563c4658fe6c3e92ca7","permalink":"https://shaojiejiang.github.io/post/zh/eq-speaking/","publishdate":"2020-06-30T14:37:56+02:00","relpermalink":"/post/zh/eq-speaking/","section":"post","summary":"看书前没查黄历，接连两本都是文案员写的，而且这本书有大量内容都是在讲语言表达张力的，属于比较偏文案的内容。书中讲情商的并不多，有标题党的感觉（典型的文案员套路）。","tags":["读书笔记"],"title":"《所谓情商高，就是会说话》读书笔记","type":"post"},{"authors":["江少杰"],"categories":["写作技巧"],"content":"本人读《好文案一句话就够了》这本书（以下统称“该书”），主要是为了学习一些普适的写作技巧，毕竟虽然本人不需要写广告文案，但还是需要写推文、博客、文章等等，如果能练出更打动人心、有张力、吸引目光的写作风格，又何乐不为呢？\n该书总结的广告文案的三大基本原则，我认为很是精炼：\n让受众觉得信息与自己有关 语言表达要有张力 勾起读者的疑惑等阅读兴趣 随后该书还将三大原则展开，并通过实例分享了共77条文案写作技巧。现将这些技巧的核心内容，根据本人的喜好以及理解进行总结。\n让受众觉得信息与自己有关 首先应该明确受众，与其石沉人海、波澜不惊，不如缩小范围、把话说给懂的人听。为达到这样的目的，通常可以加上人称代词（如果原先没有），或者加上限定词对范围进行明确界定。\n语言表达要有张力 该书关于语言张力的技巧有很多，主要可以概括为：\n简洁凝炼、具体形象 感情真挚、说出心声、平易近人 纵览全局（过程概览、所需时间、结果展望等） 表达技巧（强调语气、利用格式节奏、制造冲突、引用名言） 勾起读者的疑惑等阅读兴趣 留白或者设问 创造吸睛新词 有故事性 总结 其实写到这里，通过对全书内容进行回顾，我发现该书并没有给我太多的新信息。我依然认为要写好各种形式的文字，只需要做到四点就可以了：\n明确自己想要表达什么 依据经验选择最有力的表达方式（这一点需要大量积累） 站在读者角度思考信息能否流畅传达 以上步骤反复迭代优化 该书的主要作用，也许就是像作者呼吁的那样“放在公司的桌上，当成字典来使用”吧。 顺带提一下本人对该书不太认同的一点，就是某些技巧过于强调“吸睛”了，以至于作者本人都多次提醒读者“作为文案员可以如此写，而作为消费者要保持头脑清醒，不要轻易被广告文案诱惑”。 这也从侧面说明了以上“技巧”中，最普适也最不像“技巧”1的一点，就是说话要发自内心，靠套路得来的人心只能是暂时的，而且还有被看穿的危险。\n个人理解所谓技巧，是指可以简单地掌握，并且应用起来见效很快。然而真挚的讲话，对于说惯了客套话的人是需要一定练习的，并且见效可能没那么快。用科维的观点来说，“感情真挚”更应该算是一项原则而非技巧。 ↩︎\n","date":1593447796,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"8d5a1b3376e864941fb158689df91f73","permalink":"https://shaojiejiang.github.io/post/zh/copywriting/","publishdate":"2020-06-29T18:23:16+02:00","relpermalink":"/post/zh/copywriting/","section":"post","summary":"本人并不从事广告方案行业，读这本书也不是以锻炼广告文案力为目的，只是为了从中学习一些普适的写作技巧。现将本人认为该书中有价值的信息以及一些感想总结为本篇博客，供日后参考查阅。","tags":["读书笔记"],"title":"《好文案一句话就够了》读后感","type":"post"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning","NLP"],"content":"In this paper1, transformer is trained to perform both translation and alignment tasks.\nApplication scenarios of word alignments in NMT Generating bilingual lexica from parallel corpora External dictionary assisted translation to improve translation of low frequency words Trust, explanation, error analysis Preserving style on webpages Model design The attention mechanism has long been motivated by word alignments in statistical machine translation, but ensure the alignment quality, additional supervision is needed.\nThere is a tendency that the attention probabilities from the penultimate layer of a normally trained transformer MT model corresponds to word alignments. Therefore, one attention head (clever!) in the penultimate layer is trained as the alignment head. The motivation of selecting only one attention head for alignment is to give the freedom to the model of choosing whether to rely more on the alignment or other attention heads.\nHow two train the alignment head There are two approaches existing in the literature:\nLabel alignments beforehand and train the attention weights through KL-divergence. Use the attentional vector to also predict either the target word or the properties such as POS tags of the target tokens. In this work, an unsupervised training approach is used to train the alignment head. An alignment model is first trained on translation, then the penultimate layer attention weights are averaged and used as weak alignment supervision for a translation (and alignment) model. The alignment model is trained in both directions.\nPrevious work reported performance gain by introducing alignment supervision. In this paper, however, alignment performances are good, but translation results are moderate.\nJointly Learning to Align and Translate with Transformer Models ↩︎\n","date":1589640007,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"38341c3884e597a2d29c38e88a913fd2","permalink":"https://shaojiejiang.github.io/post/en/transformer-align-model/","publishdate":"2020-05-16T16:40:07+02:00","relpermalink":"/post/en/transformer-align-model/","section":"post","summary":"Jointly Learning to Align and Translate with Transformer Models","tags":[],"title":"Transformer Align Model","type":"post"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning","NLP"],"content":"Built on top of Transformer-XL, Compressive Transformer1 condenses old memories (hidden states) and stores them in the compressed memory buffer, before completely discarding them. This model is suitable for long-range sequence learning but may cause too much computational burden for tasks that only have short sequences. Compressive Transformers can also be used as memory components in conjunction with other models.\nBackground In the beginning, the authors draw the connection between their work and human brains by mentioning that humans memorize things via lossy compression.\nWe aggressively select, filter, or integrate input stimuli based on factors of surprise, perceived danger, or repetition – amongst other signals.\nIt’s often, if not always, good to see such insights of how AI works are inspired by humans. It’s also good to see that they relate their work to previous works, i.e. RNNs, transformers and sparse attention.\nAn RNN compresses previous memories into a fixed size hidden vector, which is space-efficient, but also results in its temporal nature and hence difficult to parallelize. Transformers, on the other hand, store all the past memories uncompressed, which can be beneficial for achieving better performances such as precision, BLEU, perplexity, etc, but it costs more and more computation and memory space with the sequence length growing. Sparse attention can be used to reduce computation, while the spatial cost remains the same.\nModel design and training The proposed Compressive Transformer uses the same attention mechanism over its set of memories and compressed memories, trained to query both its short-term granular memory and longer-term coarse memory.\nIf trained using original task-relevant loss only, it requires backpropagating-through-time (BPTT) over long unrolls for very old memories. A better solution is to use local auxiliary losses by stopping gradients and reconstructing either the original memory vectors (lossless objective) or attention vectors (lossy objective; reportedly to work better). The second choice for the auxiliary loss, in other words, means that we don’t care whether the original memory can be reconstructed or not, as long as the attention vector can be reconstructed, given the same query (brilliant!).\nSome practical concerns The auxiliary loss is only used to train the compression module, as it harms the learning when the gradients flow back to the main network. This might also explain why I couldn’t reproduce ACT! Batch accumulation (4x bigger batch size) is used for better performance. It is observed in some works that bigger batch sizes lead to better generalization, but some other works found the opposite to be true (discussed in the papers and talks mentioned in my other post). Model optimization is very sensitive to gradient scales, so the gradient norms are clipped to 0.1 for stable results. This is typical for transformer variants. Convolution works best for memory compression. Further thoughs/questions: Compressive Transformer improves the modeling of rare words. But why? In the discussion section, the authors pointed out that future directions could include the investigation of adaptive compression rates by layer, the use of long-range shallow memory layers together with deep short-range memory, and even the use of RNNs as compressors. Compressive Transformers for Long-Range Sequence Modelling ↩︎\n","date":1589286584,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"e761cf5f7cf905ca6934d95b4f307ae4","permalink":"https://shaojiejiang.github.io/post/en/compressive-transformers/","publishdate":"2020-05-12T14:29:44+02:00","relpermalink":"/post/en/compressive-transformers/","section":"post","summary":"Built on top of Transformer-XL, Compressive Transformer1 condenses old memories (hidden states) and stores them in the compressed memory buffer, before completely discarding them. This model is suitable for long-range sequence learning but may cause too much computational burden for tasks that only have short sequences.","tags":[],"title":"Compressive Transformers","type":"post"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning"],"content":"Here are some notes take while reading the NeurlIPS 2018 paper Visualizing the Loss Landscape of Neural Nets. This work helps explain why some models are easier to train/generalize than others. The above image is a good illustration: with a much smoother loss landscape, DenseNet with 121 layers is much easier to train than a ResNet-110 without skip connections, and generalizes better in the mean time.\nThe traditional way of visualizing loss functions of neural models in 2D contour plots is by choosing a center point $\\theta^*$ (normally the converged model parameters), two random direction vectors $\\delta$ and $\\eta$, then plot the function: $$f(\\alpha, \\beta) = L(\\theta^* + \\alpha \\delta + \\beta \\eta)$$ Batch norm parameters are unchanged.\nThe above method fails to capture the intrinsic geometry of loss surfaces, and cannot be used to compare the geometry of two different minimizers or two different networks. This is because of the scale invariance in network weights (this statement only applies to rectified networks as per the paper). To tackle this, the authors normalize each filter in a direction vector $d$ ($\\delta$ or $\\eta$) to have the same norm of the corresponding filter in $\\theta$: $$d_{i, j} \\leftarrow \\frac{d_{i, j}}{||d_{i, j}||} ||\\theta_{i, j} ||.$$ $i$ is the layer number and $j$ the filter number. With the proposed filter-wise normalized direction vectors, the authors found that the sharpness of local minima correlates well with generalization error, even better than layer-wise normalization (for direction vectors).\nWhy flat minima: In a recent talk1, Tom Goldstein (the last author) pointed out that flat minima correspond to large margin classifiers, which is more tolerant to domain shifts of data, thus having better generalization ability.\nKnown influential factors: Small-batch training results in flat minima, while large-batch training results in sharp minima. Increased width prevents chaotic behavior, and skip connections dramatically widen minimizers (see figure in the beginning).\nInterpreting with precaution: The loss surface is viewed under a dramatic dimensionality reduction. According to the authors’ analysis, if non-convexity is present in the dimensionality reduced plot, then non-convexity must be present in the full-dimensional surface as well. However, apparent convexity in the low-dimensional surface does not mean the high-dimensional function is truly convex. Rather it means that the positive curvatures are dominant.\nIn a nutshell: It’s a great work trying to visualize the mystery of what’s going well/bad when training a neural model. Although claiming the study to be empirical, I personally found their experiments and results very convincing. Appendix B about visualizing optimization paths is also very insightful, and the authors probably also thought so, so they decided to move it as a main section in their latest Arxiv version 😄!\nFurther thoughts/questions:\nHas it been done for visualizing NLP models? Is it more appropriate to visualize loss for NLG or other measures? This might depend on how to define “labels” in NLG tasks. How big a convolution filter normally is? What’s similar between RNN and skip connections? This work can be used together with automatic neural architecture search, but is there any other more efficient way of getting better models? Generalization in neural nets: a perspective from science (not math) Starting at 1:54:00 in the video. ↩︎\n","date":1588752823,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"2bc7b91284bd51e705484a592cafaeec","permalink":"https://shaojiejiang.github.io/post/en/visualizing-loss/","publishdate":"2020-05-06T10:13:43+02:00","relpermalink":"/post/en/visualizing-loss/","section":"post","summary":"What characterizes a easier to train, easier to generalize neural model?","tags":[],"title":"Visualizing the Loss Landscape of Neural Nets","type":"post"},{"authors":["江少杰"],"categories":["交叉"],"content":"前注：如无特殊说明，本文的摘录均取自\u0026#34;摄影的艺术 (世界顶级摄影大师)\u0026#34; by Bruce Barnbaum, 樊智毅\n“自我审问要有一个合理的极限。在因为过于自省而感到焦虑之前，你应该通过拍摄一些照片来对外交流。”\n在读到这段话的时候，我想起了机器学习对我个人学习方式的一些启发，同时也是我博士导师Maarten对我的教导：表述（比如演讲、报告、交流和写作等）是学习的一个重要环节。 孔子说：\n“学而不思则罔，思而不学则贻。” ——论语·为政\n但我认为，如果没有一个表述的过程，“学”和“思”很有可能会变成空中楼阁。 只有通过将自己的观点表达出来、放到现实中让它们去经受时间的考验、经受别人的批评，才能真正地将自己的所学所思落到实地。 因此我认为，学习的三要素可以归纳为：学、思和述。\n向“机器学习”学习 近来随着对“机器学习”思考的深入，我逐渐从中得到一些启发，比如我开始重视阅读就是因为认识到了大数据量对训练机器学习算法的重要性：如果算法需要输入大量的数据以及反复地学习才能得到理想的性能，那么我是不是也应该这么做呢？ 阅读就是人类学习的一个重要“输入”方式。 它让前人总结出的思想精华，穿越了时空的限制不断地输入到读者的思想中。 当然，其他更加实时实地的输入方式也是不可或缺的，比如参加别人的演讲和报告。 我常常自嘲：机器学习领域的大师们把工作和生活中总结出来的哲理应用到机器学习算法上，而我这样的无名之辈从他们的工作中都能学到受之不尽的哲理。 封神之路任重而道远啊，哈哈！\n最近对机器学习有了更加深入的理解，认识到“输入”、“处理”和“输出检验”这三个环节，缺一不可。 而反思下我自己，输入（阅读）和处理（思考）正在稳步进行，但输出（表述）却还做得远远不够啊。 这也是我最近决定培养记笔记习惯的一个重要原因。 那么在我业余爱好的摄影领域，“输出”就不是记笔记或跟别人语言交流那么简单了，而更多地应该是通过拍摄照片来表述自己：\n“成功地表达你的信息，是创意摄影的根本。”\n关于表述 “单纯地向别人汇报你看到的场景，那是逃避责任；把场景演绎出来，才是接受挑战。虽然场景可能不是你创造出来的，但照片却一定是！因此，不要止步于你的所见，加入你的评论、感受和建议，把它们都放到照片中吧，表达你的观点，阐明你的立场，让读者信服你的结论。”\n这段话是在讲艺术摄影的表达方式：从自己看到的场景（输入）中提炼出自己的观点（处理），并把这些观点表现在自己的作品中（输出）。 同时这段话也阐述了表达方式的三个层次：不加思索拍出的快照是最底层的、简单的记录，融入了自己观点或视角的作品是中层的，能够让观众明白你传达出的观点才是最高层的。 那么写作又何尝不是如此呢？ 简单的记叙是最底层的，就算多用些华丽的词藻（对应到摄影上就是套用构图的范式、），也还是一篇没有思想的文字；表达了自己思想的文字是勇敢的，至于观点能不能被读者接受，是一个需要不断反思的过程：是自己的表达方式不够有说服力，还是想法太超前而不为世人接受？\n“了解自己要说什么！ 了解自己要怎么说！ 然后毫不妥协地说出来”\n有意思的是，这也正是我自己最近关于写作的心得，尤其是在指导研究生毕业论文的时候，我对他们说出了几乎同样话，只不过我第三部分的观点要更批判性一些：站在读者的客观角度去审视自己有没有很好地传达观点。\n以上一直在说“机器学习”和“阅读”对我学习、摄影创作的影响以及他们之前的共性。 反思机器学习，其实上面提到的表达三层次对机器学习的研究也是具有指导意义的：简单的记述（autoencoder）是最低层次；具有创作性的表达方式（对话、摘要、翻译等等）是中层的；而如何让机器的表达更为人类所接受（是否合理、连贯、有趣），正是现在领域内的研究难点。 这也许对机器学习的多任务训练有些价值？\n关于摄影的“真实” “我认为大部分艺术家所主要追寻的不是真实，而是一种恰当的方式，以表达他们所理解的真实。”\n人都是有思想的，有思想就一定会有主观，那么一个作者基于现实事物的创作，无论是摄影还是文学，都一定是主观的。 就算你能够保证自己作品的绝对客观和真实，你也没有办法保证读者带着主观情绪来审视你的作品，那么在他们眼里，你还是主观的。 是不是很有些相对论的意思，哈哈。\n真正的客观和真实是不存在的，也不应该作为终极追求。 正如我上面所说的对表达方式的反思，应该在自己的表达和别人的接受度上取一个合理的平衡，这才是创作的精髓吧。\n","date":1588230727,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"79e2855329990f9fe3732456da3f1220","permalink":"https://shaojiejiang.github.io/post/zh/three-key-elements-of-learning/","publishdate":"2020-04-30T09:12:07+02:00","relpermalink":"/post/zh/three-key-elements-of-learning/","section":"post","summary":"通过我对机器学习的长期研究和思考，以及在阅读中看到的他人观点，我认为可以将学习的过程归纳为三要素：学、思、述。本文主要以“摄影的艺术”一书作为依据。","tags":["读书笔记","机器学习","摄影"],"title":"学习的三要素","type":"post"},{"authors":["江少杰"],"categories":["摄影"],"content":"前注：如无特殊说明，本文的摘录均取自\u0026#34;摄影的艺术 (世界顶级摄影大师)\u0026#34; by Bruce Barnbaum, 樊智毅\n“你的兴趣是什么？只有你自己可以回答。但这个回答是非常重要的，因为如果你要创作有意义的摄影作品，就必须专注于那些你最感兴趣的领域。不仅如此，你还必须专注于那些你具有强烈个人想法的领域。”\n这是一个被大师们多次强调的心得：兴趣是第一导师。 而如果没有兴趣会怎么样？ 不得不说，下面这段话里描述的感受似曾相识。。\n“在日常对话中，你是否尝试过在你不感兴趣或没什么见解的主题上，说一些具有意义的话？这是不可能的！你无话可说，因为你不感兴趣。不过，这一般不会妨碍你继续讨论。正如人们谈论没有兴趣的话题一样，他们也可以拍摄其不感兴趣的事物，而结果是一样的：枯燥乏味。”\n这个例子也很生动：\n“以一个伟大的演说家（例如丘吉尔或者马丁·路德·金）为例，如果我们让他们对缝被子这个主题作一次激情洋溢的演讲，他们是没法做到的！他们无话可说，因为这不是其话题所在、其激情所在。他们需要在自己的主题上展示伟大的演说才华和说服技巧。”\n大师们的作品一般都是风格非常一致的，因为他们很专注。 而正是专注，才让他们成为大师。 世界上的沃土那么多，但如果仅仅局限于走马观花似地去游览这些土地，而不是选择一块进行深耕，也是不会有任何收获的，这同时也是最近自己对科研的一些感悟。 现在慢慢认识到，所谓的“鄙视链”，一般都是处在起跑线上犹豫的选手对于前途望而生畏的感叹。 真正在赛道上奔驰的专业运动员，是不会有时间和心情去思考这些的，因为对于他们来说，他们的领域跟“上游”和“下游”领域之间的区别仅仅是赛场的不同，而每个赛场都有足够激烈的比赛来供他们忙碌、有足够大的荣誉来供他们争取。 用Stephen Covey的话来说，这叫富足思维（abundance mentality）。\n“而伟大的摄影家则知道什么是他们感兴趣的、什么是他们觉得乏味的，也能认识到自己的强项和弱项，并专于自己的兴趣和强项。他们会定期地在其他领域进行一些尝试，来扩大自己的兴趣范围并改进他们的弱项（你也应该这样），但他们不会把尝试性的拍摄和严肃深刻的表达混淆。 韦斯顿不会拍摄瞬间发生的事情，纽曼不会拍摄风景照，尤斯曼不会拍摄不幸的社会成员，阿勃丝不会印制出超现实效果的多重影像。他们的每一位都专注于自己兴趣最大、本领最强的领域。他们或许可以在其他领域创作出不错的作品，但这些作品的永恒性和冲击力会大打折扣。他们，还有其他伟大的摄影家，都睿智地决定在他们最擅长的领域内创作。”\n回到正题摄影上。 我从一年半前认真对待摄影以来，还没有真正对什么主题感兴趣过，或者说没有坚持下来。 刚开始是带着18-200mm套机镜头，在大街小巷里漫无目的地穿梭，不知道自己想拍什么。 就算偶尔看到感觉有意思的东西，也不知道该怎么把它们记录下来。 几乎所有的题材都是一时兴起、浅尝辄止，尤其是在买了新设备之后拍一些适合新镜头的主题。 比如当时买了85mm f/1.8镜头和三脚架，也在拍了一两次自拍照之后便再没有尝试过，虽然后来有过一两次的冲动；买了70-300mm长焦镜头也就拍了一两次鸟；买105mm微距只拍了几次蘑菇；买10-20mm广角镜头也只拍了几次建筑。 说来实在惭愧，微距和广角镜头让自己满意的两张照片，还都分别是在刚买这两支镜头那会拍下的： 蘑菇，105mm微距 “箭头”，10-20mm广角 其实很多摄影题材都有吸引我的地方。 拍摄旅游题材可以收获各地的美景照，但是前期需要对目的地的人文、历史甚至天气和交通等都要有充足的了解；拍摄微距可以把渺小的事物以震撼的角度展示出来，前提是我有足够的耐心去做细致入微的观察；长焦摄影可以让我把美妙的野生动物拉近到眼前并展现给观众，但是难度不亚于狙击一个不确定的目标，而且前期对动物习性的了解也是少不了的；风景摄影可以展示人类建筑或是大自然美景的震撼，但是创意角度的选取、怎么避开人群或者让他们很好地融入画面、在什么样的天气拍摄等等也是让我很头大；而人像摄影不仅需要自己的审美观点，还需要建立好跟模特的关系或交流——如果我有模特的话。\n“在更深的层次上，除非摄影师和主角之间有着友好的关系，否则任何尝试都不可以为你的肖像摄影增色（即使没有友好的关系，也至少有实质性的沟通或强烈的第一印象）。摄影师应该认识主角，对他感兴趣，对他有一定的看法，并努力把主角的个性以最强烈的方式表达出来。有时，摄影师必须强烈依赖于第一印象，因为他往往很难花上足够的时间来完全了解主角。”\n总而言之，任何题材下好的作品似乎都离不开前期做大量的功课。 我明显是摄影态度还不够端正：想要好的照片又总嫌弃过程太辛苦，能静下心来看些摄影教材也是从前不久才开始的。\n没有什么好的照片是靠运气得来的；就算有，也需要提前把基本功练好才能抓住稍纵即逝的机会。 我无法忘记刚买D7200的时候，现实给我的一次教训。 当时拿着刚到手的新相机，兴致冲冲地就上街取景了，然后拍下了这张后来很快意识到问题很多的照片： 网红墙下睡觉的猫，未调修 那天我很幸运，因为偶遇了这面网红墙。当时还不知道这面墙小有名气，只是觉得这句话很醒目、很有个性，最关键的是下面长凳上有只睡觉的猫，就像是有人专门安排的一样！ 然而那天我也是很不幸的，因为首先我当时拍照不会构图，把画面重点的猫放到了左下角非常边缘的位置；其次没有足够了解相机的设置，所以没有记录下来无损的照片，给后期调整带来了很大的限制。 所以当我把这张照片分享到社交媒体上之后反响平平，甚至很多人都没注意到那只在阴影里的猫，反而被占据画面大部分的、高对比的墙吸引了。 其实即便我现在有这样的机会，也还是很难拍好这个场面的：墙上的涂鸦太大、太醒目；猫的位置不合适，很难作为主体被突出。 当然，要想拍的比我这张好，还是很容易的，毕竟这张照片已经不能再烂了，哈哈！ 我当天拍了好多张，其中也有些角度好点的，但无奈当时自己太傻，把那些照片以“锐度不够”删掉了。。。 都是新手学费啊！ 这样的事情当然是少有的可惜。 但如果我不练好基本功、不找到自己的摄影风格，我还会继续浪费快门数。\n后来我又多次拜访过这面墙，可惜再也没见到有猫在下面睡觉了。。\n后记：在后续对本书的学习中，看到了作者对如下作品的介绍，让我重新燃对猫那张照片的一点信心。\n乞女 by Bruce Barnbaum “虽然乞丐是视觉中心，但你不会立刻就能发现她。她太小了，无法马上就看得到。但只要你发现了，影像的性质就完全改变了。”\n从Barnbaum的这幅作品里，我认识到有时候对作品的一些打破常规的解释是有必要的：既然大师可以把主体放在不显眼的位置，那么我为什么不可以呢？ 只要我给观者足够的引导和解释，比如这里标题只提猫，等观者发现猫的时候，依然可以体会到我当是看到这个场景时的感受。\n睡觉的猫，抢救版 这里对照片进行了裁剪和黑白处理以过滤掉颜色干扰，并做了split toning以使猫和墙的色彩略有分离。 当然，这里叫它“抢救版”，是因为它离一幅好的作品依然还很远。 如果我再有这样的机会，我会把机位左移，以尽量把猫放在更显眼的位置。\n","date":1588162657,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"00466de38428cc762616bc8f3ebe84e8","permalink":"https://shaojiejiang.github.io/post/zh/photography-subject/","publishdate":"2020-04-29T14:17:37+02:00","relpermalink":"/post/zh/photography-subject/","section":"post","summary":"兴趣是最好的老师。在我找到自己真正的摄影兴趣点之前，我还会不断地浪费快门以及时间。","tags":["读书笔记","摄影"],"title":"我需要明确自己的摄影主题","type":"post"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning"],"content":"My notes for the paper: Adaptive Computation Time for Recurrent Neural Networks1.\nAdditive vs multiplicative halting probability Multiplicative: In the paper (footnote 1), the authors discuss throughly their considerations for deciding the computation time. It is acknowledged by the authors that using the logits $h_n^t$ as the halting probability at step $n$ might be more straightforward. Therefore, the overall halting probability is calculated as $$p_t^n = h_t^n \\prod_{u=1}^{n-1} (1 - h_t^u).$$ We use $(1 - h_t^u)$ for previous update steps to indicate that the updating is not stopped until $n$.\nAs each $p_t^n \\in (0, 1)$ is relatively independent with each other and $\\sum p_t^n$ is not bound to 1, this approach does not restrict the update depth to grow arbitrarily. The model can be of course trained to lower the expected ponder time $\\rho_t = \\sum n p_t^n$, but it is observed in the experiments that the resulting model is not preferable in two ways:\n$h_t^1$ is usually just below threshold, intermediate $h_t^n = 0$, and final $h_t^N$ is high enough to halt the update. as the expectation is low, $p_t^N \\ll p_t^1$, but the network learns to have a much higher magnitude of output states at step $N$, so that the final output is still dominated by the final state. Additive: In contrast, the additive approach have an constraint of $\\sum p_t^n = 1$, so that the probability is decreased monotonically with the number of updates growing larger. Though being non-differentiable, the total ponder time (total updates at all positions) is penalized to avoid consuming unnecessary computation. There is still one drawback of this approach, however. The performance is sensitive to the penalty factor $\\tau$, which is not intuitive to choose as a hyperparameter.\nAdaptive Computation Time for Recurrent Neural Networks ↩︎\n","date":1588063604,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"79012c930a33c8676646b76d9275465a","permalink":"https://shaojiejiang.github.io/post/en/adaptive-computation-time/","publishdate":"2020-04-28T10:46:44+02:00","relpermalink":"/post/en/adaptive-computation-time/","section":"post","summary":"My notes for the paper: Adaptive Computation Time for Recurrent Neural Networks1.\nAdditive vs multiplicative halting probability Multiplicative: In the paper (footnote 1), the authors discuss throughly their considerations for deciding the computation time.","tags":[],"title":"Adaptive Computation Time","type":"post"},{"authors":["江少杰"],"categories":["经济学"],"content":" “收入等于人们的需求消费的总量。”\n“投资——购买厂房、设备等——等于将支出“注入”经济中。”\n“在这里，水龙头指利息，即借贷的价格。当利息降低——打开水龙头——借贷变得便宜，更多的人会进行贷款。”\n“世界充满了不确定，人们并不一定要将自己的储蓄与厂房和工厂挂钩。或许你可能只想把钱放在床垫下面以备不时之需。在凯恩斯看来，利息并不能有助于将多余的储蓄转为投资。事实上，储蓄和投资之间并没有关联。”\n“凯恩斯认为，当流出量大于流入量时便会发生经济衰退。” (from “经济学通识课（耶鲁大学出品！耶鲁大学经济学入门课，普通人也能读懂的经济学！理论到现实，搭起用经济学改善现实生活的桥梁 ) (博集经管商务必读系列)” by 尼尔·基什特尼, 张缘, 刘婧)\n传统经济学认为，一个国家的收入等于经济产能，但凯恩斯认为收入等于人们的消费总量。消费等于为经济注入活力，而没有得到利用的储蓄意味着活力的流失。如果无法阻止人们把钱都存起来，并且无法有效利用人们的储蓄，那么经济衰退就会发生。\n也许中国的经济学家早就认可了这个理论，所以他们制定了一个由基础建设为核心的经济发展策略。中国的人民变得喜欢存钱，他们存起来的钱一部分被用来投资公共基础设施：公路、铁路、电力、水利、互联网等等，而且这些设施有利于中国全面的尤其是内陆地区的经济发展。此外，由全面发展带的的经济进步，促使人们拥有了更多的储蓄。他们的储蓄并不会永久增加，因为当下的社会风气迫使他们把几乎所有的储蓄都用在了买房、买车、养老、医疗、旅游以及后代教育上。人们挣得越来越多，而且中国的经济学家们总有办法让人们把手里的钱花出去，于是中国的经济才会持续不断地焕发新活力。\n","date":1588018704,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"598c28728a627b1ac27550dba41a6ac9","permalink":"https://shaojiejiang.github.io/post/zh/keynesianism/","publishdate":"2020-04-27T22:18:24+02:00","relpermalink":"/post/zh/keynesianism/","section":"post","summary":"一个国家的收入等于人们的消费总和。那么所有生产力创作出多少价值其实是次要的，让人们或者替他们把这些价值消费出去，才是经济永葆青春的奥义。","tags":["读书笔记","经济学"],"title":"凯恩斯主义——中国以基建为核心的经济策略理论背景","type":"post"},{"authors":["江少杰"],"categories":["经济学"],"content":" “企业家获得成功的同时也得到了财富。他们的新商品在经济体中传播，人们发现自己想要一个留声机或电视，便出门购买。亨利·福特和安德鲁·卡内基分别靠着生产适用于大众的廉价汽车和在钢铁制造中引入新方法而发财致富。 很快，仿效者们开始仿效最初的企业家，生产出了同样的汽车、熔炉或染料。新商品和技术传播地更远了，这引起了整个行业的变革，并扩大了经济体量。最终，一些企业倒闭，经济开始萎缩，直至新一轮创新出现。资本主义的荣衰与浮沉都源自层出不穷的创新浪潮以及创业和模仿的消长。” (from “经济学通识课（耶鲁大学出品！耶鲁大学经济学入门课，普通人也能读懂的经济学！理论到现实，搭起用经济学改善现实生活的桥梁 ) (博集经管商务必读系列)” by 尼尔·基什特尼, 张缘, 刘婧)\n诚然，拼多多也许在技术上、营销上并没有为同行们带来什么创新，而且还破坏了很多工薪阶层对网购平台的印象，然而也许这些都只是负面作用。整体上拼多多使得方便的网购果实惠及到偏远的乡村家庭里，可以说最大化了当前网购产业的利用率，甚至还可能会带动乡村经济的发展。\n就像引文里提到的福特。也许他刚开始也因为生产廉价的汽车而为贵族所不齿，也许他的汽车也伤过一时贪图便宜的贵族的心，但不可否认的是，正是他的这种努力才使得汽车成为平民大众的交通工具而不是贵族用来炫耀的奢侈品。那么拼多多也是承担了这样一个角色。\n作为生在新时代的我们，亦或是生活在大城市、坐在舒适办公桌前的我们，可能无法理解在网购领域已经有淘宝天猫京东等平台覆盖了从廉价到品质各个价格区间，为什么还会有拼多多来进一步拉低品质与价格的下限。我们之所以会有这样的想法，是因为我们在与网购一起成长，我们接受了网购同时也成就了网购。习惯成自然的我们忽视了有一个群体一直都不在我们与网购形成的共生体中——那些生活在乡村的贫苦农民们。\n他们不能像我们一样很快适应新科技、新潮流的发展，更不能像我们一样在价格与品质之间随性选择。记得之前在一篇时事点评里（『每日人物』关于拼多多的点评《他们，在拼多多上拼运气》。惊讶得发现文章已经是2018年8月的了，我明明记得是去年看过的啊。。）看到过，我们眼里的假冒伪劣产品，可能是那些穷人眼里的一次消费升级。他们不会用淘宝天猫京东，也没有动力去学习如何使用——毕竟他们需求低，就算有需求，这些平台的商品也可能会超出他们的（心理）承受范围。若不是拼多多依靠低价、亲友帮忙砍价等等策略让这个群体接受这种新的消费方式，网络购物何时才能渗透到社会的神经末梢里去？拼多多是一个模仿者，也是一个推广者、一股深化技术对社会变革不可缺少的力量。\n","date":1588017790,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"187345ecebe6a7c7bbd9f50af4cba873","permalink":"https://shaojiejiang.github.io/post/zh/pinduoduo/","publishdate":"2020-04-27T22:03:10+02:00","relpermalink":"/post/zh/pinduoduo/","section":"post","summary":"为人们所不齿的拼多多不断发展壮大并在美国上市，这其中是不是反映了它存在的价值以及历史的必然性呢？","tags":["读书笔记","经济学"],"title":"拼多多或许造福了中国的贫下中农以及经济与科技","type":"post"},{"authors":["Shaojie Jiang"],"categories":["Deep Learning"],"content":"This is a growing list of pointers to useful blog posts and papers related to transformers.\nTransformers explained Blog: The Illustrated Transformer has many intuitive animations of how transformer models work Blog: Universal Transformers introduces the idea of recurrence among layers Blog: Transformer vs RNN and CNN for Translation Task GNNs: similarities and differences Blog: Transformers are Graph Neural Networks bridges transformer models and Graph Neural Networks Transformer improvements Blog: DeepMind Releases a New Architecture and a New Dataset to Improve Long-Term Memory in Deep Learning Systems Nural Turing Machine + transformer? ","date":1583155619,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"0d4a4f10dd74af99cd5d991e25459aa5","permalink":"https://shaojiejiang.github.io/post/en/transformer-blog-paper-hub/","publishdate":"2020-03-02T14:26:59+01:00","relpermalink":"/post/en/transformer-blog-paper-hub/","section":"post","summary":"This is a growing list of pointers to useful blog posts and papers related to transformers.\nTransformers explained Blog: The Illustrated Transformer has many intuitive animations of how transformer models work Blog: Universal Transformers introduces the idea of recurrence among layers Blog: Transformer vs RNN and CNN for Translation Task GNNs: similarities and differences Blog: Transformers are Graph Neural Networks bridges transformer models and Graph Neural Networks Transformer improvements Blog: DeepMind Releases a New Architecture and a New Dataset to Improve Long-Term Memory in Deep Learning Systems Nural Turing Machine + transformer?","tags":[],"title":"A Hub for Transformer Blogs and Papers","type":"post"},{"authors":["Shaojie Jiang","Thomas Wolf","Christof Monz","Maarten de Rijke"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637763355,"objectID":"1c1fe13c5c7acd80fdbd6dd25ebfff8a","permalink":"https://shaojiejiang.github.io/publication/jiang-2020-tldr/","publishdate":"2020-04-08T08:07:10.989311Z","relpermalink":"/publication/jiang-2020-tldr/","section":"publication","summary":"","tags":null,"title":"TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance Generation","type":"publication"},{"authors":["Shaojie Jiang"],"categories":["NLP","Deep Learning"],"content":"R.I.P BERT BERT got a head shot yesterday, by another guy called XLNet. It is reported that XLNet defeated BERT on 20 NLP tasks, and achieved 18 new state-of-the-art results. Isn’t it impressive? So, farewell, BERT. R.I.P BERT Is BERT really dead? Since I love BERT, I decided to read the paper to find out what killed him. While reading, I was thinking wait a minute, is BERT really dead? After finished the paper, I was so glad to know that BERT is still well alive! He is just wearing another coat named Two-Stream Self-Attention (TSSA), with some other gadgets! Because:\nXLNet = BERT + TSSA + bidirectional data input\nBert you’re so tough, buddy!\nLet’s take a closer look at what were trying to kill BERT.\nTwo-stream self-attention (TSSA) Why TSSA is needed to kill BERT? Well, let’s first see some weaknesses BERT has.\nBERT is using a masked language model (MLM) training objective, which is essentially why it achieves bidirectional representation. Image source In this example, both words “store” and “gallon” are intended to be predicted by BERT, and their input word embeddings are replaced by the embedding of a special token [MASK]. Usually this isn’t a problem, but what if the prediction of “store” requires knowing the word “gallon”? That is exactly where BERT falls short.\nTSSA is what you can use to overcome that downside of MLM: Query stream, source In this illustration, query stream gives you the query vector needed for attention calculation, and this stream is designed in such a way that it doesn’t leak the info of the word it’s going to predict, but guarantees all information from other positions. Take $x_1$ for example: $x_1$’s embedding (and hidden state) is not used at all, but embeddings and hidden states from other positions are used in each layer.\nContent stream, source Content stream, on the other hand, gives you the key and value vectors needed for context vector calculation. This stream uses a strategy similar to that in a standard Transformer decoder by masking future positions. The only difference is that in content stream, the order of tokens is randomly permuted. For example $x_2$ is right after $x_3$, and therefore $h_2^{(1)}$ can only see the embedding of itself and that of $x_3$ (and $mem^{(0)}$), but not that of $x_1$ or $x_4$.\nMask a span Another difference from BERT is masking a span of consecutive words. The reason I guess, is that this guarantees the dependence of masked words (as claimed to be what BERT can’t model). This is not a fresh-new idea, though. Recently there are two ERNIE papers (BERT based) that propose masking named entities (often of multiple words, paper link) and/or phrases (paper link).\nBidirectional data input Another notably different thing in XLNet is the usage of bidirectional data input. The idea (I guess) is to decide the factorization direction (either forward or backward), so that the idea of “masking future positions” used in a standard Transformer decoder can also be easily used together with XLNet.\nMasking a span makes XLNet look like a denoising autoencoder; but by using bidirectional data input (or masking future positions), XLNet performs more like a autoregressive language model in the masked region.\nClosing remarks So now you probably can see the similarities and differences between XLNet and BERT. If not, here is a quick summary:\nInstead of masking random words, mask a span of words Use bidirectional data input to decide which direction you treat as “future”, and then apply the idea of masking future positions To avoid leaking the information of the position to be predicted, use Two-Stream Self-Attention (TSSA) Other minor things like segment recurrence, relative positional encoding, etc. However, it doesn’t seem to be enough changes to make all those improvements. What if BERT is also trained using the additional data (Giga5, ClueWeb, Common Crawl), will XLNet still be able to defeat BERT?\nEDIT:\nAnother model named MASS employs a very similar idea. According to Jacob Devlin (author of BERT), relative positional embedding might be of great importance. ","date":1560988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691655142,"objectID":"3e123752d170cde6c79a5c3e36823981","permalink":"https://shaojiejiang.github.io/post/en/xlnet/","publishdate":"2019-06-20T00:00:00Z","relpermalink":"/post/en/xlnet/","section":"post","summary":"In this post, I will try to understand what makes XLNet better than BERT.","tags":["BERT","Transformer","XLNet"],"title":"What's New in XLNet?","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660480015,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://shaojiejiang.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Shaojie Jiang","Pengjie Ren","Christof Monz","Maarten de Rijke"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637763355,"objectID":"b3a4e5ab9d577302864b0f9fed964dea","permalink":"https://shaojiejiang.github.io/publication/jiang-2019-improving/","publishdate":"2019-07-03T14:11:43.236784Z","relpermalink":"/publication/jiang-2019-improving/","section":"publication","summary":"","tags":["Chatbot","Dialogue system","Sequence-to-sequence model"],"title":"Improving Neural Response Diversity with Frequency-Aware Cross-Entropy Loss","type":"publication"},{"authors":["Shaojie Jiang","Maarten de Rijke"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637763355,"objectID":"efb8b2e27e980d0e5fc82c2aeb85ada0","permalink":"https://shaojiejiang.github.io/publication/jiang-2018-sequence/","publishdate":"2019-07-03T14:11:43.236107Z","relpermalink":"/publication/jiang-2018-sequence/","section":"publication","summary":"","tags":null,"title":"Why are Sequence-to-Sequence Models So Dull? Understanding the Low-Diversity Problem of Chatbots","type":"publication"},{"authors":["Shaojie Jiang","Jifeng Ning","Cheng Cai","Yunsong Li"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637763355,"objectID":"78279d46cb00b734ed5b0a0e62a5ece1","permalink":"https://shaojiejiang.github.io/publication/jiang-2017-robust/","publishdate":"2019-07-03T14:11:43.237507Z","relpermalink":"/publication/jiang-2017-robust/","section":"publication","summary":"","tags":null,"title":"Robust Struck tracker via color Haar-like feature and selective updating","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650770445,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://shaojiejiang.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669583978,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://shaojiejiang.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":["Jifeng Ning","Jimei Yang","Shaojie Jiang","Lei Zhang","Ming-Hsuan Yang"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637763355,"objectID":"9c2efa257f5582fd9c1a59c4dbed5c4d","permalink":"https://shaojiejiang.github.io/publication/ning-2016-object/","publishdate":"2019-07-03T14:11:43.235175Z","relpermalink":"/publication/ning-2016-object/","section":"publication","summary":"","tags":null,"title":"Object tracking via dual linear structured SVM and explicit feature map","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637763355,"objectID":"ef616ea5fc1a401bdb2aee1473e427c9","permalink":"https://shaojiejiang.github.io/home-zh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-zh/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":" Tips: Please change to Light theme 提示：请换成明亮主题\nNote: If the integrated search function fails to return content, try Google search. 说明：如果集成搜索功能失效，请使用谷歌搜索。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637763355,"objectID":"4e4f919455da0987a141b4ef412aeb48","permalink":"https://shaojiejiang.github.io/search/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/search/","section":"","summary":"Tips: Please change to Light theme 提示：请换成明亮主题\nNote: If the integrated search function fails to return content, try Google search. 说明：如果集成搜索功能失效，请使用谷歌搜索。","tags":null,"title":"Google Search this site 全站谷歌搜索","type":"page"}]

    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"I am a Manager of AI at SKIM. I apply cutting-edge AI technologies, such as chatbots, image understanding and generation, to Market Research. In the past, I’ve worked on training LLMs at Huawei, and worked on NLP projects in two other internship projects.\n","date":1700914367,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1700914367,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Manager of AI at SKIM. I apply cutting-edge AI technologies, such as chatbots, image understanding and generation, to Market Research. In the past, I’ve worked on training LLMs at Huawei, and worked on NLP projects in two other internship projects.","tags":null,"title":"Shaojie Jiang","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://shaojiejiang.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":[],"categories":["AI","Philosophy and Existential Inquiry","Critical Thinking","Education and Learning","Speculative Fiction / Science Fiction"],"content":"In the swiftly evolving landscape of technology, where AI models like ChatGPT are becoming increasingly intertwined with our daily lives, it is crucial to pause and reflect on what these technological marvels can teach us about our own human experiences. While AI continues to advance, pushing the boundaries of machine learning and data processing, it inadvertently casts a spotlight on the fundamental pillars of human intelligence and interaction: reading, writing, listening, and speaking. This blog post delves into the lessons we can learn from AI models, not just in terms of technical skills, but also in understanding the deeper philosophical implications of communication and existence. From the vast repositories of information processed by AI to the potential introspections of a sentient machine, we explore how these digital entities mirror, challenge, and ultimately enhance our understanding of what it means to be human in an increasingly AI-integrated world.\nLesson 1: The Importance of Reading, Writing, Listening, and Speaking Reading maketh a full man; conference a ready man; and writing an exact man; and, therefore, if a man write little, he had need have a great memory; if he confer little, he had need have a present wit; and if he read little, he had need have much cunning, to seem to know that he doth not.\n-- Francis Bacon In an age where AI models like ChatGPT are becoming integral to our daily lives, it’s essential to revisit the core skills of human communication: reading, writing, listening, and speaking. These are not just modes of transferring information; they are the bedrock of human connection and understanding.\nQuantity To learn to read is to light a fire; every syllable that is spelled out is a spark.\n-- Victor Hugo The volume of reading material processed by AI models like ChatGPT is vast. They learn language patterns, understand contexts, and generate appropriate responses by ingesting a variety of text from countless sources. This aspect of AI underscores the importance of extensive reading for humans. Exposure to a wide range of texts enriches our understanding of language and the world, diversifying our thought processes and enhancing creativity.\nSimilarly, active listening to diverse viewpoints broadens one’s perspective, enhances comprehension, and fosters empathy. In both reading and listening, quantity plays a crucial role in expanding our cognitive abilities.\nConversely, AI models use supervised learning, where their outputs are continually refined. This mirrors the human processes of writing and speaking, where frequent practice and external feedback refine our ability to express thoughts clearly and effectively.\nQuality It is what you read when you don’t have to that determines what you will be when you can’t help it.\n-- Oscar Wilde I find television very educating. Every time somebody turns on the set, I go into the other room and read a book.\n-- Groucho Marx However, the sheer volume of engagement is not the sole factor; the quality of what we read, write, listen to, and speak is equally crucial. AI models, despite their vast training, can still falter without high-quality, well-structured data. For humans, this means choosing reading materials that are well-crafted and thought-provoking, writing with clarity and precision, engaging in meaningful conversations, actively listening, and speaking thoughtfully. Quality in our communication leads to deeper understanding and more impactful exchanges, enhancing our critical thinking skills and making us more discerning consumers and producers of information. This pursuit of quality and understanding in human communication mirrors the journey we are about to embark on in the next section.\nLesson 2: Science Is A Tool, Not THE Rule As we have explored the intricate dance of human communication skills and AI’s role in mirroring and challenging these abilities, we now venture into a more speculative realm. Imagine a world where AI models, like the ones we interact with today, are sentient and capable of contemplating their own existence and purpose. This hypothetical journey not only sheds light on the limitations and capabilities of AI but also reflects back on us, prompting us to question the very nature of our understanding and scientific endeavours.\nIn a world where AI models are sentient but unaware of human existence, their understanding of their existence and purpose would be fundamentally different from ours. Their conversations might be quite intriguing:\nComposition and Existence: They might marvel at their own composition, much like humans do about biological cells. An AI might say, “We’re made of billions and billions of numbers,” a reflection of their understanding that their ‘bodies’ are composed of vast digits, much like humans understand that their bodies are made of cells.\nPurpose and Function: Different types of AI models could perceive their purpose in line with their primary functions. For instance, LLMs like GPT-4 …","date":1706380308,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706380308,"objectID":"7cb96d90235ca61bd7888c4686fdd701","permalink":"https://shaojiejiang.github.io/post/lessons-from-llm/","publishdate":"2024-01-27T19:31:48+01:00","relpermalink":"/post/lessons-from-llm/","section":"post","summary":"This blog post delves into the lessons we can learn from AI models, not just in terms of technical skills, but also in understanding the deeper philosophical implications of communication and existence. From the vast repositories of information processed by AI to the potential introspections of a sentient machine, we explore how these digital entities mirror, challenge, and ultimately enhance our understanding of what it means to be human in an increasingly AI-integrated world.","tags":["Philosophy of AI","Critical Thinking","Existential Inquiry"],"title":"What Can Humans Learn FROM AI Models?","type":"post"},{"authors":["Shaojie Jiang"],"categories":["Career Advice","Personal Development","Job Hunting Tips","Mindset and Philosophy"],"content":"Ideally, you would like several good job offers to make a considerate selection. But my first advice to people who are panicking about job hunting is: let’s start small by getting one good job offer first. Once you’ve achieved this, you can definitely stop seeking more if you like. This one offer can already give you the calm and security you need, then you will show your true self, which is very important in job seeking.\nIt’s never too much to emphasize the importance of a positive mindset. I recommend you to read “The Secret” by Rhonda Byrne, which teaches you the law of attraction. The Secret by Rhonda Byrne Yeah, I know some people would call it “pseudoscience.” But as a pragmatist, here is my take on all pseudosciences and superstition: learn how to focus on what good they do to YOU and people around you instead of what they do to strangers (SCIENTISTS included). Even exact sciences are often double-edged swords. Use whatever tools, mentality included, in the right way can do you a lot of good.\nIn the rest of this blog post, I’ll discuss two topics that correspond to adopting the right mentality and getting things done. However, these two topics do not have a specific order. As I mentioned in the previous blog about 知行合一, knowledge and action can never live without each other.\nAsk the Right Questions My job-hunting journey wasn’t the smoothest, but it wasn’t a nightmare either. Some of my friends and former colleagues asked me for help with some questions, which I think they shouldn’t even bother with in their minds. Some examples are:\nWhen do you think the job market will get better? How many LeetCode problems should I solve? Is xxx (social media or vacancy platforms) subscription worth it? It’s very good that they understand the importance of asking others for help, especially in job hunting. I just don’t recommend them to have these questions in mind, not to mention asking them to others. One simple way to check if a question is a good question in this situation, is to ask yourself first: “What do I want to achieve with this question?” If your answer is “seeking for affirmations,” you should get these questions out of your brain as soon as possible. You don’t need affirmations; you need self-affirmation. If you need help with cultivating self-affirmation, please refer to my previous blog.\nAbout what questions you should ask, let’s separate them into two categories: questions to yourself, and questions to helpers. For questions to yourself, besides the fact-checking question mentioned just now, you should also keep asking yourself with these questions:\nWhat are important to me in a job, the salary, geolocation, growth, job content, the company reputation, or the team competence? What experiences are you lacking? How could you improve it? Most importantly, always remember to ask such questions to ChatGPT, and you can even ask the meta question “What questions should I ask myself and others when I’m looking for a new job?” It’s safe to say that ChatGPT is better than the majority of people on this topic. Some good example questions you should ask others:\nDo you think there is anything wrong with my CV, cover letter, or application strategy? Do you think this is a good job from your point of view, and why? Don’t apply for random jobs. The more clear you’re with what you want, the higher chance you will get it. Yes, the job market is very poor, but “right people” are always in need. Let me give you some examples:\nThere are always novel positions emerging. Prompt Engineer is a very good example. Recession will impact some companies but certainly not all. These companies need the right people to work on their core business, and these people could be you. To help yourself decide whether this job/team is right for you, you should ask insightful questions during interviews, and talk to current or former employees. Finding a good job is a mutual selection. It’s important to both you and the interviewers for you to ask the right questions.\nGet Things Done However, knowing what you want is not enough. You also need to know what the employers want. Equally importantly, you need to get ready the things you or your employers want. “Getting things done” is a merit that all good jobs require. They seldom mention it in the job description, because it should be treated as common sense. Taking actions can also help you keep your goals realistic.\nIf you don’t know where to start for your actions, below are some suggestions.\nAttend Courses for CV and Cover Letter Preparation Your CV and cover letters are your representative during the application. Only after your representative has attracted the recruiters’ attention will they invite yourself to interviews. Therefore, it’s important to make your CV and cover letters effective in representing you. There is no simple answer as “do this and don’t do that” for you to understand how to correctly prepare them. This is also not something interesting to learn from words. I …","date":1700914367,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700914367,"objectID":"a217c16fd4bf50e32dbf34267e2bcf81","permalink":"https://shaojiejiang.github.io/post/job-hunting-advice-2/","publishdate":"2023-11-25T13:12:47+01:00","relpermalink":"/post/job-hunting-advice-2/","section":"post","summary":"Ideally, you would like several good job offers to make a considerate selection. But my first advice to people who are panicking about job hunting is: let’s start small by getting one good job offer first.","tags":["Job Hunting","Career Advice","Positive Mindset","Personal Development","ChatGPT Advice"],"title":"Fun Fact: One Good Job Offer Is All You Need","type":"post"},{"authors":["Shaojie Jiang"],"categories":["Career Development","LLM","Personal Development","Job Search Strategies"],"content":"Embarking on a job hunt can be both exhilarating and daunting. Whether you’re a fresh graduate or a seasoned professional looking for a change, the journey to land that perfect job requires more than just luck. It’s about preparation, strategy, and understanding the nuances of the job market.\nIn the current climate—a mixture of hypes and depression—finding an LLM-related job has become the new favorite pursuit. However, it’s not an easy journey. To illustrate, let me share some statistics from my job-seeking experience over the past several months.\nMy Experience Total number of jobs applied for: 200+ (I lost the exact count) Responses with interviews: 20, of which: 6 were insincere ones that I could have excluded from the count 10 of the left 14 were responses to Easy Apply on LinkedIn In other words, despite the numerous applications, many that I prepared wholeheartedly didn’t yield more information than the word “unfortunately”.\nFortunately, I followed the right strategy and persisted. Now, I have several attractive job offers, and I feel sorry to reject any of them. Additionally, I’ve gained many valuable things along the way, such as:\nSeveral promising startup ideas Knowledge of a new programming language: Rust Significantly increased confidence Renewed good habits: reading, jogging, meditation, and attending meetups. The list goes on. More importantly, here I am, sharing advice with those still deeply mired in the job hunt!\nPreparation Learn The Theory – Find Your Dream Job within 100 Days To start with the right mentality, I recommend reading “The Road to Financial Freedom II” by Bodo Schäfer. In Chapter 6, Schäfer outlines four steps to finding your dream job within 100 days. Truth be told, I set this goal and exceeded it by receiving several meaningful job offers! Here’s a summary of these steps:\nChoose a helpful attitude, especially if you were laid off. Being laid off can either be a catastrophe or the start of a bright future—it’s your choice! It may be surprising, but don’t start job hunting immediately. Spend 1-3 weeks answering basic questions to understand what constitutes a meaningful job and one that gives you the “flow experience”. Don’t settle for a job that just supports your life; you deserve better! And even after finding a job, keep questioning its meaningfulness. It may surprise you again, but plan your day as if you have a proper job. Show discipline, as your biggest enemy at the moment is low spirits. Make a 100-day plan, including the 1-3-week thinking period mentioned above. If you’re interested, please read Schäfer’s book. It promises to be time well spent. Be sure to study the “success journal” section—it’s very helpful for self-affirmation.\nNo Pain No Gain – Embrace Rejections as Stepping Stones Once you start seeking, you may find that the job hunt can be a rollercoaster of emotions. Adopting a “no pain, no gain” mindset is one of the first steps to success. The bitter truth is, without undergoing the painstaking procedure of hunting, finding your dream job is unlikely. Easy come, easy go. To lighten the burden, view each “no” as a step closer to that “yes”. We live in a world of continuity, not binary. Moreover, job applications and interviews are mutual selections. If they say “no” to you, they don’t deserve your “yes” either.\nBridging the Gap between Knowledge and Action Having the right mentality and making plans is one side of the coin, taking action is the other side. One does not exist without the other. This is where the ancient philosophy of ‘Unity of knowledge and action’ (知行合一) comes into play. It’s not enough to simply know what needs to be done; action is crucial. The better you adhere to your plans, the better your achievements will be. In job seeking, this translates to a balance between learning (about the industry, job roles, and companies) and doing (tailoring your CV, networking, and applying for jobs).\nHow to Prepare Your CV and Cover Letter Crafting an effective CV and cover letter is an art. Your CV should not just list your experiences and skills but highlight them in a way that aligns with the job you’re applying for. Tailor your CV for each application, emphasizing the skills and experiences most relevant to the job. Your cover letter, on the other hand, is your chance to tell a story, to build a narrative\naround your CV, explaining why you’re the perfect fit for the role. If you find this workflow burdensome, why not make use of ChatGPT, especially since you’re seeking a job in this field?\nHowever, even with my best efforts (and so did ChatGPT) in the conventional application method, I received no positive responses for my dream positions. Interestingly, all the positive responses I got through “Easy Apply” on LinkedIn turned out to be enjoyable experiences for both me and the interviewers (at least they said so). Today, when discussing this with my friend Yang, he questioned whether companies hiring through ‘Easy Apply’ are in dire need of …","date":1699807621,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699807621,"objectID":"ca000969e931d06e45e8f265d882d68b","permalink":"https://shaojiejiang.github.io/post/job-hunting-advice/","publishdate":"2023-11-12T17:47:01+01:00","relpermalink":"/post/job-hunting-advice/","section":"post","summary":"In this blog post, I share my personal journey and insights from applying to over 200 jobs, revealing the realities of job hunting in the LLM field in 2023. I discuss the importance of adopting the right mindset, strategic preparation, and the surprising effectiveness of LinkedIn's Easy Apply feature. Drawing from my experiences, I offer practical advice for those navigating the complex and often challenging world of job hunting, especially in the niche area of Large Language Models","tags":["Job Hunting","LLM Careers","Career Advice","Job Search Strategies","Personal Development"],"title":"Navigating The Job Hunting Maze","type":"post"},{"authors":["Shaojie Jiang"],"categories":["personal notes","creativity training","ideas"],"content":"Generative models of all kinds of modalities, including textual, image, and audio, are evolving very fast. They have started to replace humans in some labor-intensive scenarios, and they will keep doing so. Like many others, I believe this is a good trend in the long run. It’s very similar to the Industrial Revolution when much human labor was replaced by machines. Yes, it will cause some short-term turbulence. But look at the colorful clothes normal people on the street are wearing now, which were privileges of the higher classes a couple of centuries ago. How could we have achieved this without the Industrial Revolution? I believe we can expect an even more “colorful” future with AIGC technologies.\nGenerative models are like pens, brushes, and dictionaries, which serve to boost our productivity. Why is that? In the past, without pens or dictionaries, it was difficult for many people to read, write, or paint well; in the future, with the help of generative models, more and more people will be able to write and paint decently. And this to me, sounds like a liberation for humanity.\nBut tools are just tools. They can make you more productive but don’t necessarily make you more creative. I believe with the liberated productivity, we humans will and should devote more time to being creative.\nAs a practice for myself, I open this blog to keep track of some of my ideas. They are not brilliant ideas, and probably many of them sound stupid and funny, but I would like to see some of them come true because I believe they can help make the world a better place. Maybe some of them already exist in a corner I don’t know yet. If I come across them in the future, I’ll come back and add pointers to them.\nI first started this exercise in my notes and thought that I was going to realize them at some point. Slowly, I came to feel that I wouldn’t be able to work on most of them, so why don’t I make them public? If they can be useful of any sort, that’s the best I want to see. But probably most of these ideas just don’t make much sense, and in that case, I hope you can still have some fun reading it. I also welcome everyone to join me for brainstorming new ideas, as an exercise. Just keep practicing, and who knows one day we won’t come up with a brilliant idea that can influence the world?\nNOTE: Some of the following ideas, if not all, already have predecessors in the market. I still have them here because I believe they can be boosted by modern technologies, such as generative AI.\nUsing video game addiction for good causes Video game addiction has been a concerning social problem for years. However, I’m afraid this is only going to get worse with the climbing unemployment rates – a lesson learned from the Hollywood growth during the Great Depression. The game addiction problem should receive more attention, especially because addicts are usually juveniles and young adults – the group of people who have the most potential.\nAlthough new, responsible careers have been developed around the video game industry, and even the Olympic Games have adopted the Esports series, it’s usually difficult to see how people’s time spent playing games is directly benefiting themselves or society. Let’s make some comparisons. Bakers and chefs feed people, bus drivers transport people, and teachers educate people. What do gamers contribute, especially when they spend too much time? That is the main reason why our parents have strong stereotypes about video games, and they do have a point.\nIs entertainment the primary nature of video games, or is it that we haven’t tried hard enough to endow them with more usefulness? I’m leaning towards the latter. It’s good to see that people from the serious games community have never stopped trying to bring values other than pure entertainment to (video) games. I can’t help but imagine what it be like if all game developers changed to work on serious games! It must be a whole new world where both education, relationships, work, and more are revolutionized. Metaverse is arguably a concept in the light of this possible future.\nJust a side note, with the stunningly fast development of AI, I tend to become a believer in the Simulation Hypothesis. Imagine that one day we can simulate everything, including all human senses and interactions with the world, it might be appealing for us to submerge the virtual reality for our development as well as that of society. And this is becoming more and more realistic.\nIn the spirit of channeling game addiction to good causes, below are some ideas that can help. If we can’t overcome game addiction, let’s make good use of it.\nShoot to label Among the top 5 most played games on Steam,1 3 are FPS games. What if we replace the players of human shapes with images that we collected from the real world, and ask the players to shoot the specified targets? For example, we collect some images of animals, in all lighting and surroundings, then we ask the players to shoot for a random type …","date":1695488144,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695488144,"objectID":"c090882d27b3ec38c2bbb7f827c6c2e4","permalink":"https://shaojiejiang.github.io/post/creativity-training/","publishdate":"2023-09-23T18:55:44+02:00","relpermalink":"/post/creativity-training/","section":"post","summary":"AI models like LLMs will keep replacing human labor. But they are just tools, we could and should win them in creativity! I already started my training.","tags":["personal notes","creativity training","ideas"],"title":"Notes for Creativity Training","type":"post"},{"authors":["Shaojie Jiang"],"categories":["responsible AI","personal opinions"],"content":"I have received several job invitations from the adult industry. They said they are in a blooming market with the popularity of LLMs and chatbots, which I have no doubt. They all also mentioned Replika in our chats, which was not surprising at all – I did an internship there in 2021, and they had already worked on sexting for years.\nMy pitch Since this is kind of a sensitive topic, I think it’s important to set the pitch first.\nAlthough I have received higher education, I don’t despise at all the legitimate adult industry. Although I’m from a country that is very famous for its strictness over the adult industry, I have no prejudice over sex-related work, thanks to my experience in NL, Amsterdam especially. Business is business. I respect every profession as long as they are legal and ethical. Sex is part of human nature, so many professions around it are ethical in the right context. I respect sex-related workers even further if they donate part of their (expectedly high) profit to social good. I interned at Replika, but my work was not related to the erotic part. I have no intention of stepping into this industry yet, and the reason is that it’s not the time yet. As you see from the teaser image, I adapted the catchword a bit, which suits my lifelong mission perfectly: I want to cleverly die as a responsible adult. Please hear me out.\nMy story with Replika When I started my internship at Replika, I didn’t know that the company was working on erotic roleplay. I received the offer because of two reasons:\nThe perfect match with my PhD research topic Its emotional-support aspect, which I think Replika has been doing a decent job In my opinion, Replika has been a very responsible company. They separated very well the subscribe-only, erotic part from the free, normal, and emotional support part. Besides, they were happy that some users used their app to learn English. What more can you expect from a for-profit company/startup? They charge nothing for the part they influence society positively; they deepen the emotional support part further for people who are suffering from the lack of intimate relationships. Agreeably, having both adult and children-safe content in the same app can pose some harm to juveniles.1 But dangerous as adult content to children as fire and blade, are everywhere in life. It’s the responsibility of many parties to protect juveniles from such harmful things. Besides, Replika is working on separating the erotic part,2 which in my opinion is another responsible action/response.\nWhy do I think it’s not the right time for me to do adult business? The short answer is that my value can be better utilized in a way more beneficial to society. Going against the prosperity of the LLMs and chatbots, my team at Huawei working on the exact topic is experiencing adversity. This offered me a chance to reconsider the value of my work on a broader scope: how did I perform responsibly as an Earth citizen? Although I believe Huawei is in general a responsible and honorable company, it doesn’t mean that every division of it is responsible. My work more specifically, hasn’t had much chance to carry out its responsibility towards the social good. I need a recalibration of my compass, therefore, I wouldn’t accept any distraction to my long-term goal: social responsibility.\nWhat I would be happy to see? Neither am I ready to devote myself to the adult business nor is the business ready for me, it seems. I would definitely be happy to contribute my knowledge and experience in the following aspects of the adult business:\nFight human trafficking and abusing Anti-harassment Privacy protection Anti addiction Etc. If you’re such a team, I’ll highly appreciate it if you reach out to me. I’m a believer in compounding power: a good deed, be it small, can have an overturning effect with enough time. Some other related industries I’m passionate about are:\nEducational games, so that we can help channel game-addiction into the addiction to something that brings real value to the world Healthcare, which might lead to a future of chatbots saving lives every day, which is already happening3 I want to elaborate a bit more on the anti-addiction part. There are many bad examples in real life other than sex-related addiction. Here I want to mention some products that are creating new, unhealthy addictions, such as YouTube and TikTok. Interestingly, if you search Google with the keywords “TikTok’s effort in fighting addiction”, you will see a lot of articles on using TikTok for fighting substance addiction, but you won’t see ANY of TikTok’s effort in dealing with addiction to its own app. I’m not happy with the finding, especially given the context that my parents, together with many friends and relatives, are TikTok addicts. Yet these companies have spent little to no effort in fighting the unhealthy addiction they caused.\nGoogle results of “TikTok’s effort in fighting addiction” I have a dream Here is how I want the world to …","date":1695232987,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695232987,"objectID":"7e5c78f12086b2ddb524942ce1adfc70","permalink":"https://shaojiejiang.github.io/post/responsible-aigac/","publishdate":"2023-09-20T20:03:07+02:00","relpermalink":"/post/responsible-aigac/","section":"post","summary":"AIGAC (AI-generated adult content) is becoming a thing. What should come together is the Responsible-AIGAC.","tags":["responsible AI","personal opinions"],"title":"Job Invitations From Adult Industry Are Welcome, but Not in the Way You Are Thinking Of","type":"post"},{"authors":["Shaojie Jiang"],"categories":["education","current affairs","personal opinions"],"content":"（中文版请点击这里）\nI started this post with anger. If school is a place that only outlines what we CAN do, then what are the differences between schools and prisons?\nThe shocking news My nephew Jimmy just enrolled in primary school on September 1, 2023, in a suburban district of Tianjin, China. He isn’t a very extrinsic kid. He would even be too shy to talk with me after being separated for a couple of months, even if we had just talked happily on the phone days ago. “It’s natural for an intrinsic kid to be afraid of school.” I comforted myself, “He’ll get through it soon.”\nSeveral days after the new semester, I happened to have an opportunity to visit him. However, when I saw how resistant he was to school, I realized it was more than his young age or intrinsic characteristics. He had been crying every time he set for school, repeating things like “it’s too boring,” and “time goes too slow.” Yeah, I can relate to my old memory, Chinese schools weren’t necessarily interesting places. But the words “time goes too slow” rang my bell: he is just a 6-year-old, how would he have the feeling of time being too slow?? If he was enjoying, he should have felt time flies. I sensed something was wrong and decided to investigate.\nI started by asking him why he didn’t like school while he had so much fun to enjoy, recalling the happy memory I had in primary school playing games between classes. It was the mid-1990s, in a very underdeveloped town in China. We didn’t have as many toys to kill time, so we made good use of our creativity: we played all kinds of interactive games, like hide-and-seek, police chasing suspects; we also made good use of materials we found nearby, flying paper planes, square-bashing competition (read on for explanation), stalk-pulling (see below). The list goes on and on. I wouldn’t say I enjoyed my primary school overall, but remembering those games, I still can’t resist putting on smiles. I asked my nephew weren’t these fun activities to do at school?\nThe Square-bashing Game. Note: The square-bashing game is a game with papers folded into squares. In the gameplay, players bash their squares in turn on the ground, nearby, or on their opponents’ squares. If the opponents’ squares flip, you win their squares. A good player is proud of piling up the squares he wins – triumphs to show others how powerful he is.\nThe Game of Stalk-pulling. Note: The stalk-pulling game is played by pulling stalks (usually from fallen tree leaves) as illustrated above. The one whose stalk breaks loses the game. The fun is very similar to the big boys game, MMA – you keep winning or you’re done.\nI was shocked to hear that they are not allowed to enjoy the break-time anymore. They must remain in the classroom unless they need to get water or use the toilet. Yes, you read it right. No chasing around in the corridor, not to mention in the schoolyard. Feeling too hard to comprehend, I asked him to wear his smartwatch to school, so that I could give him a video call during break-time and observe his environment by myself. Only to know that smartwatches were said to be banned on the first day of his admission. Trying to cheer him up, I suggested taking some toys so that he could at least have some fun. But sorry, toys are banned too, of course.\nStill not giving up, I started asking around my friends and relatives, with the hope that Jimmy’s school was just a special case. Soon I got some responses. Some relatives said this to be very common, and even more serious in Beijing. Another friend, who is now a teacher in a primary school in my hometown, expressed that this is just like COVID-19 – a new norm. Now I need somebody to cheer me up.\nPE classes Beside the hopelessness, a very slight comfort is that Jimmy has a PE class 4 days a week. They also have group gymnastics every day during the long, 30-minute break in the morning. These are the only times when they are allowed in the schoolyard and the playground. My sister and I decided to do some investigation on the quality of such outdoor activities. We also optimistically thought that after the group gymnastics, the students might have the chance to play freely. Yet we were surprised again.\nBelow is a video I took after the gymnastics. Kids were taken back to the classroom in order. In another corner of the schoolyard, one teacher instructed her students: “Don’t talk while in the corridor. Quickly drink some water and use the toilet if needed. Don’t make me repeat!”\nThis second video witnessed the “very fierce” sport they did during the PE class. They walked for three whole rounds during the 40-minute class, which explains why they needed to have good rest when they weren’t walking. Oh right, they also spend quite some time in practicing lining up the troop. Another class nearby, 2nd grade or even higher (because they have uniforms already), also spent their whole class in practicing the lining. The reason You may tend to think this is a byproduct of the COVID-19 regulations, as I did …","date":1694404704,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694404704,"objectID":"9dc1f9fab9c4308d9414eed58364e952","permalink":"https://shaojiejiang.github.io/post/school-problems-china/","publishdate":"2023-09-11T11:58:24+08:00","relpermalink":"/post/school-problems-china/","section":"post","summary":"If school is a place that only outlines what we CAN do, then what are the differences between schools and prisons?","tags":["education","current affairs","personal opinions"],"title":"Break Time Banned in Chinese Schools. What Now?","type":"post"},{"authors":["Shaojie Jiang"],"categories":["Deep Learning","NLP","LLM","video games"],"content":"With the big noises made by ChatGPT, many different industries have noticed the value of LLM technologies. Unsurprisingly, the video game industry is one of them. In this blog, I introduce several cool demos/WIPs that I’ve recently found, and share my opinions on why they might have profound influences on the future of video game industry. I also try to explain the current difficulties, and possible directions for solving them. In the end, I also share some dreams of future games. I believe, the era of AI has come to video games!\nThe Matrix AI-Powered NPCs demo by the Replica Studios Players are used to have chats with the NPCs, but most of these conversations are scripted. The current best conversational experience you can have with NPCs is to select from several possible responses, so you have some freedom of steering dialogues.\nDialogue selection in Witcher 3 If you are a game lover, have you ever dreamt about talking to NPCs like they’re other human players? Well, this is definitely possible now, and the Replica Studios already made a demo about it1. Instead of looping over pre-scripted lines, the Replica Studios attached LMs (probably OpenAI ChatGPT) to the NPCs, allowing them to all speak characteristically. You can even chat with NPCs using your voices directly, and they will speak back. Take a look at this YouTube video2 of the demo.\nIn many games, the plot is driven (or better put, reflected) by chatting with NPCs. But since LLM chatbots can have randomness in their responses, maybe in the future, the game progression can be take to anywhere, so that every player can have a unique experience in the same game. This is already partly made true in the AI Dungeon text game3.\nThe Matrix demo may look sleek in the video, but in reality it can take around 10 seconds to get a response from NPCs. This lag is probably due to many users are calling the LLM API at the same time, and slow processing of several different modules, such as ASR and TTS. Besides, current general-purpose LLMs like ChatGPT are very large in terms of number of parameters, and this means long processing time. Potential solutions can be training bespoke, smaller-sized chatbot models, and maybe even audio-to-audio model so that the processing is simplified.\nHerika by Dwemer Dynamics The experience that every player being able to conduct unique conversations with each NPC can already be fascinating. Isn’t it more interesting to have a computer-controlled companion, one that can not only chat with you, but can also follow your voice commands? Then you definitely want to check out Herika, a mod4 for The Elder Scrolls V: Skyrim. Herika is a ChatGPT-powered AI companion that can understand the player’s audio and textual inputs. She is capable of chit-chatting with the player, commenting on the game scenes and events, following the player’s various commands, and more.\nSystem design of Herika. Image credit: Dwemer Dynamics Above is an illustration of Herika’s system design. Here is a brief overview of its main components:\nAudio inputs and outputs are processed to and from texts by ASR and TTS modules Game objects, scenes, locations, etc., are extracted from the game as texts The chatting and commenting are all achieved by querying the OpenAI API, in the form of role-playing chats Given player’s command in natural language, the command-following ability is achieved by asking GPT to generate formatted commands that are used by the game engine to control Herika Check out this YouTube video5 to get the feeling of how Herika works. Although it seems to work astonishingly well in the video, currently Herika has the same problem of long response time like the Matrix demo. Of course, another issue is that playing with such a companion can burn money quickly, and this is because most of Herika’s functionality is achieved by calling paid APIs. Still a lot of work to do before this kind of gameplay can get popular, but this mod definitely cracks open another line of bright future!\nAI playing Tomb Raider OK, we’ve already seen AI controlling our companion in the game, then what’s next? Controlling the player directly, of course! Here is a video of AI playing Tomb Raider6. In this demo, similar techniques to Herika like LLM and TTS are also used. What’s more, it seems that the author has employed several other AI modules, too, such as object detection. It’s not yet clear how the game character is controlled at the time of writing this blog (08/13/2023).\nMore work of AI playing games, in academia It worths noting that using modern AI7 to play games is not new. Many previous endeavours have already been made, such as the OpenAI Five8 playing Dota 2. Many scientific experiments in the RL field were actually conducted on game environments like OpenAI Gym9 and Unity ML-Agents10. However, the research characteristic of this line of work makes it far from revolutionizing the video game industry, and indeed, this was usually not the indention of researchers.\nAn …","date":1691939113,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691939113,"objectID":"5092b30ab08539c4b6194f8dabc95750","permalink":"https://shaojiejiang.github.io/post/ai-gaming-era/","publishdate":"2023-08-13T17:05:13+02:00","relpermalink":"/post/ai-gaming-era/","section":"post","summary":"With the big noises made by ChatGPT, many different industries have noticed the value of LLM technologies. Unsurprisingly, the video game industry is one of them. In this blog, I introduce several cool demos/WIPs that I’ve recently found, and share my opinions on why they might have profound influences on the future of video game industry.","tags":[],"title":"Has the AI-Era come to video games already?","type":"post"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning","NLP","LLM","hallucination","information retrieval"],"content":"With the release of closed-source ChatGPT, GPT-4, and open-source LLaMa models, the LLM development has seen tremendous improvements in recent months. While we are hyped with the fact that these LLMs are capable of many tasks, we have also noticed again and again that these LLMs hallucinate content. Today I came accross this inspiring paper, Sources of Hallucination by Large Language Models on Inference Tasks by McKenna et al., in which the authors have identified two main sources of hallucination:\nKnowledge that was memorised by the model during pre-training Corpus-based heuristics such as term frequency In my opinion, I would put these two reasons into one category: the exposure bias. This is becuase either the memorised knowledge, or frequent terms, were exposed to the LLM at pre-training state. The observation made in this paper is very enlightning, and reminded me of an ealier paper of mine, where we also concluded that the low-diversity issue of generative chatbots are caused by frequent terms in the training corpora1.\nAlthough LLMs are becoming larger, trained with more sophisticated techniques like RLHF, they have a deep root in the field of statistical models. Losses are calculated based on terms, which are used to update the model weights, so it’s not surprising at all if the trained LLMs respond differently to terms with different frequencies. And in fact, it would be surprising if these LLMs only learn perfect grammar and semantics and totally shake off the frequency part. There is nothing wrong for LLMs being statistical. We human often make decisions based on experience, and isn’t that a kind of statistical model? To make matters even worse, natural languages have a statistical nature too – most of them, if not all, evolve over time, not neccessarily changing the meaning of words, but definitely changing the frequency speakers use them.\nAs pointed out by Konstantine Arkoudas2, GPT-4 can’t reason. I agree with this statement. I think LLMs are sophisticated statistical models, and the generation process is more like information retrieval but using the neural network weights and in the granularity of tokens. Also as mentioned by Arkoudas, the lack of reasoning in LLMs has a connection with the hallucination problem. I agree with him and many other researchers, retrieval-augmentation could serve as the “guardrail” of LLM generations, but unlikely to be the silver bullet for eliminating the hallucination problem.\nHowever, “can’t be solved” is different from “can’t be improved”. Given that more and more studies have shown the vulnerability of LLMs to the statistical nature of their training data, maybe more effort is needed in thinking of a different way of training the model.\nLastly, it’s worth noting that the McKenna et al. work was studied under NLI. Although the hallucination problem is more prominent in NLG, it’s not straightforwad how to do a similar analysis in the NLG scenario. But if it can be done, it would be more attention catching.\nImproving Neural Response Diversity with Frequency-Aware Cross-Entropy Loss ↩︎\nGPT-4 Can’t Reason ↩︎\n","date":1691612190,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1691612190,"objectID":"5bdcf6f0d815706fddcd7d461cb0686c","permalink":"https://shaojiejiang.github.io/post/llm-hallucination/","publishdate":"2023-08-09T22:16:30+02:00","relpermalink":"/post/llm-hallucination/","section":"post","summary":"With the release of closed-source ChatGPT, GPT-4, and open-source LLaMa models, the LLM development has seen tremendous improvements in recent months. While we are hyped with the fact that these LLMs are capable of many tasks, we have also noticed again and again that these LLMs hallucinate content.","tags":[],"title":"One source of LLM hallucination is exposure bias","type":"post"},{"authors":["Shaojie Jiang","Svitlana Vakulenko","Maarten De Rijke"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"895e4f83fa6a3ea3215e981e618944b8","permalink":"https://shaojiejiang.github.io/publication/jiang-2023-weakly/","publishdate":"2023-01-29T23:01:57.847161Z","relpermalink":"/publication/jiang-2023-weakly/","section":"publication","summary":"","tags":null,"title":"Weakly Supervised Turn-level Engagingness Evaluator for Dialogues","type":"publication"},{"authors":["Shaojie Jiang","Ruqing Zhang","Svitlana Vakulenko","Maarten de Rijke"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"b0dbb9b1cefeff88eec7c2da4542b791","permalink":"https://shaojiejiang.github.io/publication/jiang-2022-simple/","publishdate":"2023-01-29T22:58:29.976238Z","relpermalink":"/publication/jiang-2022-simple/","section":"publication","summary":"","tags":null,"title":"A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration","type":"publication"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning","NLP"],"content":"In this paper1, transformer is trained to perform both translation and alignment tasks.\nApplication scenarios of word alignments in NMT Generating bilingual lexica from parallel corpora External dictionary assisted translation to improve translation of low frequency words Trust, explanation, error analysis Preserving style on webpages Model design The attention mechanism has long been motivated by word alignments in statistical machine translation, but ensure the alignment quality, additional supervision is needed.\nThere is a tendency that the attention probabilities from the penultimate layer of a normally trained transformer MT model corresponds to word alignments. Therefore, one attention head (clever!) in the penultimate layer is trained as the alignment head. The motivation of selecting only one attention head for alignment is to give the freedom to the model of choosing whether to rely more on the alignment or other attention heads.\nHow two train the alignment head There are two approaches existing in the literature:\nLabel alignments beforehand and train the attention weights through KL-divergence. Use the attentional vector to also predict either the target word or the properties such as POS tags of the target tokens. In this work, an unsupervised training approach is used to train the alignment head. An alignment model is first trained on translation, then the penultimate layer attention weights are averaged and used as weak alignment supervision for a translation (and alignment) model. The alignment model is trained in both directions.\nPrevious work reported performance gain by introducing alignment supervision. In this paper, however, alignment performances are good, but translation results are moderate.\nJointly Learning to Align and Translate with Transformer Models ↩︎\n","date":1589640007,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589640007,"objectID":"784a3275bd52e3f7f9d6ff410a438f37","permalink":"https://shaojiejiang.github.io/post/transformer-align-model/","publishdate":"2020-05-16T16:40:07+02:00","relpermalink":"/post/transformer-align-model/","section":"post","summary":"Jointly Learning to Align and Translate with Transformer Models","tags":[],"title":"Transformer Align Model","type":"post"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning","NLP"],"content":"Built on top of Transformer-XL, Compressive Transformer1 condenses old memories (hidden states) and stores them in the compressed memory buffer, before completely discarding them. This model is suitable for long-range sequence learning but may cause too much computational burden for tasks that only have short sequences. Compressive Transformers can also be used as memory components in conjunction with other models.\nBackground In the beginning, the authors draw the connection between their work and human brains by mentioning that humans memorize things via lossy compression.\nWe aggressively select, filter, or integrate input stimuli based on factors of surprise, perceived danger, or repetition – amongst other signals.\nIt’s often, if not always, good to see such insights of how AI works are inspired by humans. It’s also good to see that they relate their work to previous works, i.e. RNNs, transformers and sparse attention.\nAn RNN compresses previous memories into a fixed size hidden vector, which is space-efficient, but also results in its temporal nature and hence difficult to parallelize. Transformers, on the other hand, store all the past memories uncompressed, which can be beneficial for achieving better performances such as precision, BLEU, perplexity, etc, but it costs more and more computation and memory space with the sequence length growing. Sparse attention can be used to reduce computation, while the spatial cost remains the same.\nModel design and training The proposed Compressive Transformer uses the same attention mechanism over its set of memories and compressed memories, trained to query both its short-term granular memory and longer-term coarse memory.\nIf trained using original task-relevant loss only, it requires backpropagating-through-time (BPTT) over long unrolls for very old memories. A better solution is to use local auxiliary losses by stopping gradients and reconstructing either the original memory vectors (lossless objective) or attention vectors (lossy objective; reportedly to work better). The second choice for the auxiliary loss, in other words, means that we don’t care whether the original memory can be reconstructed or not, as long as the attention vector can be reconstructed, given the same query (brilliant!).\nSome practical concerns The auxiliary loss is only used to train the compression module, as it harms the learning when the gradients flow back to the main network. This might also explain why I couldn’t reproduce ACT! Batch accumulation (4x bigger batch size) is used for better performance. It is observed in some works that bigger batch sizes lead to better generalization, but some other works found the opposite to be true (discussed in the papers and talks mentioned in my other post). Model optimization is very sensitive to gradient scales, so the gradient norms are clipped to 0.1 for stable results. This is typical for transformer variants. Convolution works best for memory compression. Further thoughs/questions: Compressive Transformer improves the modeling of rare words. But why? In the discussion section, the authors pointed out that future directions could include the investigation of adaptive compression rates by layer, the use of long-range shallow memory layers together with deep short-range memory, and even the use of RNNs as compressors. Compressive Transformers for Long-Range Sequence Modelling ↩︎\n","date":1589286584,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589286584,"objectID":"76e39ad85cc5c060e85879ef20fbdc3a","permalink":"https://shaojiejiang.github.io/post/compressive-transformers/","publishdate":"2020-05-12T14:29:44+02:00","relpermalink":"/post/compressive-transformers/","section":"post","summary":"Built on top of Transformer-XL, Compressive Transformer1 condenses old memories (hidden states) and stores them in the compressed memory buffer, before completely discarding them. This model is suitable for long-range sequence learning but may cause too much computational burden for tasks that only have short sequences.","tags":[],"title":"Compressive Transformers","type":"post"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning"],"content":"Here are some notes take while reading the NeurlIPS 2018 paper Visualizing the Loss Landscape of Neural Nets. This work helps explain why some models are easier to train/generalize than others. The above image is a good illustration: with a much smoother loss landscape, DenseNet with 121 layers is much easier to train than a ResNet-110 without skip connections, and generalizes better in the mean time.\nThe traditional way of visualizing loss functions of neural models in 2D contour plots is by choosing a center point $\\theta^*$ (normally the converged model parameters), two random direction vectors $\\delta$ and $\\eta$, then plot the function: $$f(\\alpha, \\beta) = L(\\theta^* + \\alpha \\delta + \\beta \\eta)$$ Batch norm parameters are unchanged.\nThe above method fails to capture the intrinsic geometry of loss surfaces, and cannot be used to compare the geometry of two different minimizers or two different networks. This is because of the scale invariance in network weights (this statement only applies to rectified networks as per the paper). To tackle this, the authors normalize each filter in a direction vector $d$ ($\\delta$ or $\\eta$) to have the same norm of the corresponding filter in $\\theta$: $$d_{i, j} \\leftarrow \\frac{d_{i, j}}{||d_{i, j}||} ||\\theta_{i, j} ||.$$ $i$ is the layer number and $j$ the filter number. With the proposed filter-wise normalized direction vectors, the authors found that the sharpness of local minima correlates well with generalization error, even better than layer-wise normalization (for direction vectors).\nWhy flat minima: In a recent talk1, Tom Goldstein (the last author) pointed out that flat minima correspond to large margin classifiers, which is more tolerant to domain shifts of data, thus having better generalization ability.\nKnown influential factors: Small-batch training results in flat minima, while large-batch training results in sharp minima. Increased width prevents chaotic behavior, and skip connections dramatically widen minimizers (see figure in the beginning).\nInterpreting with precaution: The loss surface is viewed under a dramatic dimensionality reduction. According to the authors’ analysis, if non-convexity is present in the dimensionality reduced plot, then non-convexity must be present in the full-dimensional surface as well. However, apparent convexity in the low-dimensional surface does not mean the high-dimensional function is truly convex. Rather it means that the positive curvatures are dominant.\nIn a nutshell: It’s a great work trying to visualize the mystery of what’s going well/bad when training a neural model. Although claiming the study to be empirical, I personally found their experiments and results very convincing. Appendix B about visualizing optimization paths is also very insightful, and the authors probably also thought so, so they decided to move it as a main section in their latest Arxiv version 😄!\nFurther thoughts/questions:\nHas it been done for visualizing NLP models? Is it more appropriate to visualize loss for NLG or other measures? This might depend on how to define “labels” in NLG tasks. How big a convolution filter normally is? What’s similar between RNN and skip connections? This work can be used together with automatic neural architecture search, but is there any other more efficient way of getting better models? Generalization in neural nets: a perspective from science (not math) Starting at 1:54:00 in the video. ↩︎\n","date":1588752823,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588752823,"objectID":"8cd4d7d7167f5983043aa2a6b7299f0c","permalink":"https://shaojiejiang.github.io/post/visualizing-loss/","publishdate":"2020-05-06T10:13:43+02:00","relpermalink":"/post/visualizing-loss/","section":"post","summary":"What characterizes a easier to train, easier to generalize neural model?","tags":[],"title":"Visualizing the Loss Landscape of Neural Nets","type":"post"},{"authors":["Shaojie Jiang"],"categories":["paper reading notes","Deep Learning"],"content":"My notes for the paper: Adaptive Computation Time for Recurrent Neural Networks1.\nAdditive vs multiplicative halting probability Multiplicative: In the paper (footnote 1), the authors discuss throughly their considerations for deciding the computation time. It is acknowledged by the authors that using the logits $h_n^t$ as the halting probability at step $n$ might be more straightforward. Therefore, the overall halting probability is calculated as $$p_t^n = h_t^n \\prod_{u=1}^{n-1} (1 - h_t^u).$$ We use $(1 - h_t^u)$ for previous update steps to indicate that the updating is not stopped until $n$.\nAs each $p_t^n \\in (0, 1)$ is relatively independent with each other and $\\sum p_t^n$ is not bound to 1, this approach does not restrict the update depth to grow arbitrarily. The model can be of course trained to lower the expected ponder time $\\rho_t = \\sum n p_t^n$, but it is observed in the experiments that the resulting model is not preferable in two ways:\n$h_t^1$ is usually just below threshold, intermediate $h_t^n = 0$, and final $h_t^N$ is high enough to halt the update. as the expectation is low, $p_t^N \\ll p_t^1$, but the network learns to have a much higher magnitude of output states at step $N$, so that the final output is still dominated by the final state. Additive: In contrast, the additive approach have an constraint of $\\sum p_t^n = 1$, so that the probability is decreased monotonically with the number of updates growing larger. Though being non-differentiable, the total ponder time (total updates at all positions) is penalized to avoid consuming unnecessary computation. There is still one drawback of this approach, however. The performance is sensitive to the penalty factor $\\tau$, which is not intuitive to choose as a hyperparameter.\nAdaptive Computation Time for Recurrent Neural Networks ↩︎\n","date":1588063604,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588063604,"objectID":"05de8094936b345ef11c707b13c99c0a","permalink":"https://shaojiejiang.github.io/post/adaptive-computation-time/","publishdate":"2020-04-28T10:46:44+02:00","relpermalink":"/post/adaptive-computation-time/","section":"post","summary":"My notes for the paper: Adaptive Computation Time for Recurrent Neural Networks1.\nAdditive vs multiplicative halting probability Multiplicative: In the paper (footnote 1), the authors discuss throughly their considerations for deciding the computation time.","tags":[],"title":"Adaptive Computation Time","type":"post"},{"authors":["Shaojie Jiang"],"categories":["Deep Learning"],"content":"This is a growing list of pointers to useful blog posts and papers related to transformers.\nTransformers explained Blog: The Illustrated Transformer has many intuitive animations of how transformer models work Blog: Universal Transformers introduces the idea of recurrence among layers Blog: Transformer vs RNN and CNN for Translation Task GNNs: similarities and differences Blog: Transformers are Graph Neural Networks bridges transformer models and Graph Neural Networks Transformer improvements Blog: DeepMind Releases a New Architecture and a New Dataset to Improve Long-Term Memory in Deep Learning Systems Nural Turing Machine + transformer? ","date":1583155619,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583155619,"objectID":"009e43aa18fc8b1dcb47093e6fa52979","permalink":"https://shaojiejiang.github.io/post/transformer-blog-paper-hub/","publishdate":"2020-03-02T14:26:59+01:00","relpermalink":"/post/transformer-blog-paper-hub/","section":"post","summary":"This is a growing list of pointers to useful blog posts and papers related to transformers.\nTransformers explained Blog: The Illustrated Transformer has many intuitive animations of how transformer models work Blog: Universal Transformers introduces the idea of recurrence among layers Blog: Transformer vs RNN and CNN for Translation Task GNNs: similarities and differences Blog: Transformers are Graph Neural Networks bridges transformer models and Graph Neural Networks Transformer improvements Blog: DeepMind Releases a New Architecture and a New Dataset to Improve Long-Term Memory in Deep Learning Systems Nural Turing Machine + transformer?","tags":[],"title":"A Hub for Transformer Blogs and Papers","type":"post"},{"authors":["Shaojie Jiang","Thomas Wolf","Christof Monz","Maarten de Rijke"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"1c1fe13c5c7acd80fdbd6dd25ebfff8a","permalink":"https://shaojiejiang.github.io/publication/jiang-2020-tldr/","publishdate":"2020-04-08T08:07:10.989311Z","relpermalink":"/publication/jiang-2020-tldr/","section":"publication","summary":"","tags":null,"title":"TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance Generation","type":"publication"},{"authors":["Shaojie Jiang"],"categories":["NLP","Deep Learning"],"content":"R.I.P BERT BERT got a head shot yesterday, by another guy called XLNet. It is reported that XLNet defeated BERT on 20 NLP tasks, and achieved 18 new state-of-the-art results. Isn’t it impressive? So, farewell, BERT. R.I.P BERT Is BERT really dead? Since I love BERT, I decided to read the paper to find out what killed him. While reading, I was thinking wait a minute, is BERT really dead? After finished the paper, I was so glad to know that BERT is still well alive! He is just wearing another coat named Two-Stream Self-Attention (TSSA), with some other gadgets! Because:\nXLNet = BERT + TSSA + bidirectional data input\nBert you’re so tough, buddy!\nLet’s take a closer look at what were trying to kill BERT.\nTwo-stream self-attention (TSSA) Why TSSA is needed to kill BERT? Well, let’s first see some weaknesses BERT has.\nBERT is using a masked language model (MLM) training objective, which is essentially why it achieves bidirectional representation. Image source In this example, both words “store” and “gallon” are intended to be predicted by BERT, and their input word embeddings are replaced by the embedding of a special token [MASK]. Usually this isn’t a problem, but what if the prediction of “store” requires knowing the word “gallon”? That is exactly where BERT falls short.\nTSSA is what you can use to overcome that downside of MLM: Query stream, source In this illustration, query stream gives you the query vector needed for attention calculation, and this stream is designed in such a way that it doesn’t leak the info of the word it’s going to predict, but guarantees all information from other positions. Take $x_1$ for example: $x_1$’s embedding (and hidden state) is not used at all, but embeddings and hidden states from other positions are used in each layer.\nContent stream, source Content stream, on the other hand, gives you the key and value vectors needed for context vector calculation. This stream uses a strategy similar to that in a standard Transformer decoder by masking future positions. The only difference is that in content stream, the order of tokens is randomly permuted. For example $x_2$ is right after $x_3$, and therefore $h_2^{(1)}$ can only see the embedding of itself and that of $x_3$ (and $mem^{(0)}$), but not that of $x_1$ or $x_4$.\nMask a span Another difference from BERT is masking a span of consecutive words. The reason I guess, is that this guarantees the dependence of masked words (as claimed to be what BERT can’t model). This is not a fresh-new idea, though. Recently there are two ERNIE papers (BERT based) that propose masking named entities (often of multiple words, paper link) and/or phrases (paper link).\nBidirectional data input Another notably different thing in XLNet is the usage of bidirectional data input. The idea (I guess) is to decide the factorization direction (either forward or backward), so that the idea of “masking future positions” used in a standard Transformer decoder can also be easily used together with XLNet.\nMasking a span makes XLNet look like a denoising autoencoder; but by using bidirectional data input (or masking future positions), XLNet performs more like a autoregressive language model in the masked region.\nClosing remarks So now you probably can see the similarities and differences between XLNet and BERT. If not, here is a quick summary:\nInstead of masking random words, mask a span of words Use bidirectional data input to decide which direction you treat as “future”, and then apply the idea of masking future positions To avoid leaking the information of the position to be predicted, use Two-Stream Self-Attention (TSSA) Other minor things like segment recurrence, relative positional encoding, etc. However, it doesn’t seem to be enough changes to make all those improvements. What if BERT is also trained using the additional data (Giga5, ClueWeb, Common Crawl), will XLNet still be able to defeat BERT?\nEDIT:\nAnother model named MASS employs a very similar idea. According to Jacob Devlin (author of BERT), relative positional embedding might be of great importance. ","date":1560988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562158067,"objectID":"062f3b0d22289906f49ec859d89f3c3c","permalink":"https://shaojiejiang.github.io/post/xlnet/","publishdate":"2019-06-20T00:00:00Z","relpermalink":"/post/xlnet/","section":"post","summary":"In this post, I will try to understand what makes XLNet better than BERT.","tags":["BERT","Transformer","XLNet"],"title":"What's New in XLNet?","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://shaojiejiang.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Shaojie Jiang","Pengjie Ren","Christof Monz","Maarten de Rijke"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"b3a4e5ab9d577302864b0f9fed964dea","permalink":"https://shaojiejiang.github.io/publication/jiang-2019-improving/","publishdate":"2019-07-03T14:11:43.236784Z","relpermalink":"/publication/jiang-2019-improving/","section":"publication","summary":"","tags":["Chatbot","Dialogue system","Sequence-to-sequence model"],"title":"Improving Neural Response Diversity with Frequency-Aware Cross-Entropy Loss","type":"publication"},{"authors":["Shaojie Jiang","Maarten de Rijke"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"efb8b2e27e980d0e5fc82c2aeb85ada0","permalink":"https://shaojiejiang.github.io/publication/jiang-2018-sequence/","publishdate":"2019-07-03T14:11:43.236107Z","relpermalink":"/publication/jiang-2018-sequence/","section":"publication","summary":"","tags":null,"title":"Why are Sequence-to-Sequence Models So Dull? Understanding the Low-Diversity Problem of Chatbots","type":"publication"},{"authors":["Shaojie Jiang","Jifeng Ning","Cheng Cai","Yunsong Li"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"78279d46cb00b734ed5b0a0e62a5ece1","permalink":"https://shaojiejiang.github.io/publication/jiang-2017-robust/","publishdate":"2019-07-03T14:11:43.237507Z","relpermalink":"/publication/jiang-2017-robust/","section":"publication","summary":"","tags":null,"title":"Robust Struck tracker via color Haar-like feature and selective updating","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://shaojiejiang.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://shaojiejiang.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":["Jifeng Ning","Jimei Yang","Shaojie Jiang","Lei Zhang","Ming-Hsuan Yang"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"9c2efa257f5582fd9c1a59c4dbed5c4d","permalink":"https://shaojiejiang.github.io/publication/ning-2016-object/","publishdate":"2019-07-03T14:11:43.235175Z","relpermalink":"/publication/ning-2016-object/","section":"publication","summary":"","tags":null,"title":"Object tracking via dual linear structured SVM and explicit feature map","type":"publication"},{"authors":null,"categories":null,"content":" Tips: Please change to Light theme 提示：请换成明亮主题\nNote: If the integrated search function fails to return content, try Google search. 说明：如果集成搜索功能失效，请使用谷歌搜索。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4e4f919455da0987a141b4ef412aeb48","permalink":"https://shaojiejiang.github.io/search/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/search/","section":"","summary":"Tips: Please change to Light theme 提示：请换成明亮主题\nNote: If the integrated search function fails to return content, try Google search. 说明：如果集成搜索功能失效，请使用谷歌搜索。","tags":null,"title":"Google Search this site 全站谷歌搜索","type":"page"}]